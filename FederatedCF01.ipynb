{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedCF01.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdurahman02/AcademicContent/blob/master/FederatedCF01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTxiepTsL9Je"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFNIvhWhMK1_",
        "outputId": "b86913ef-0ead-4481-ccb9-118c72194dcb"
      },
      "source": [
        "!git clone \"https://github.com/abdurahman02/ml-latest-small.git\"\n",
        "os.chdir(\"ml-latest-small\")\n",
        "os.listdir()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-latest-small'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.txt', 'tags.csv', '.git', 'ratings.csv', 'movies.csv', 'links.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnYWGgDzb4BN"
      },
      "source": [
        "data = pd.read_csv(\"ratings.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OkCQhz6Oculg",
        "outputId": "25303b8e-8b4d-42f8-d9dc-fcc0c61a25df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea326e11-8172-4eb1-bd0c-154ef36c86c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea326e11-8172-4eb1-bd0c-154ef36c86c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea326e11-8172-4eb1-bd0c-154ef36c86c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea326e11-8172-4eb1-bd0c-154ef36c86c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filtering_data(df,from_user, to_user, from_item, to_item):\n",
        "  if(from_user <= to_user and from_item <= to_item\n",
        "     and to_user < max(df[\"userId\"]) and to_item < max(df[\"movieId\"])\n",
        "     ):\n",
        "    return df[(df.userId >= from_user) & \n",
        "              (df.userId <= to_user) &\n",
        "              (df.movieId >= from_item) &\n",
        "              (df.movieId <= to_item)\n",
        "              ]\n",
        "  print(\"Error Range\")\n",
        "\n",
        "def getBatchForUser(data, u, batchSize):\n",
        "  if u >= len(data[\"userId\"].unique()):\n",
        "    print(\"INvalid UserId requested\")\n",
        "    return\n",
        "  if batchSize > len(data[data.userId == u]):\n",
        "    batchSize = len(data[data.userId == u])\n",
        "  return data[data.userId == u].sample(n=batchSize)"
      ],
      "metadata": {
        "id": "EKMuzxOjV4BK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGV2LLrqcxCl"
      },
      "source": [
        "# split train and validation before encoding\n",
        "# np.random.seed(3)\n",
        "# msk = np.random.rand(len(data)) < 0.8\n",
        "# train = data[msk].copy()\n",
        "# val = data[~msk].copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al49AgtXc2m3"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DmYZDpc4_V"
      },
      "source": [
        "# here is a handy function modified from fast.ai\n",
        "def proc_col(col, train_col=None):\n",
        "    \"\"\"Encodes a pandas column with continous ids. \n",
        "    \"\"\"\n",
        "    if train_col is not None:\n",
        "        uniq = train_col.unique()\n",
        "    else:\n",
        "        uniq = col.unique()\n",
        "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
        "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)\n",
        "    \n",
        "def encode_data(df, train=None):\n",
        "    \"\"\" Encodes rating data with continous user and movie ids. \n",
        "    If train is provided, encodes df with the same encoding as train.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col_name in [\"userId\", \"movieId\"]:\n",
        "        train_col = None\n",
        "        if train is not None:\n",
        "            train_col = train[col_name]\n",
        "        _,col,_ = proc_col(df[col_name], train_col)\n",
        "        df[col_name] = col\n",
        "        df = df[df[col_name] >= 0]\n",
        "    return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTs0H8ysc7Vk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtAUKwkLe5J8"
      },
      "source": [
        "# encoding the train and validation data\n",
        "# df_train = encode_data(train)\n",
        "# df_val = encode_data(val, train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_val.movieId.values"
      ],
      "metadata": {
        "id": "L8L215wIoPR4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train_numpy = df_train.to_numpy(dtype=int, copy=True)\n",
        "# # print((df_train_numpy))\n",
        "# diction={}\n",
        "# for i in range(len(df_train_numpy)):\n",
        "#   diction[df_train_numpy[i][0],df_train_numpy[i][1]] = df_train_numpy[i][2]"
      ],
      "metadata": {
        "id": "HueUy7FsS4YB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GruLv6NteLdk"
      },
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, userX_embedding, item_embed_mat, emb_size=100):\n",
        "        super(MF, self).__init__()\n",
        "        self.userX_embedding = userX_embedding\n",
        "        self.item_embed_mat = item_embed_mat\n",
        "        # print(userX_embedding.weight)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        u = self.userX_embedding(u)\n",
        "        \n",
        "        v = self.item_embed_mat(v)\n",
        "        # print(\"u: \",u)\n",
        "        # print(\"v: \",v)\n",
        "        # print(len((u*v).sum(1)))\n",
        "        return (u*v).sum(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb_size=5\n",
        "# items = torch.LongTensor(df_train.movieId.unique()) #.cuda()\n",
        "# embx_item = nn.Embedding(num_items, emb_size)\n",
        "# embx_user = nn.Embedding(1,emb_size)\n",
        "# embx_user.weight.data.uniform_(0, 0.05)\n",
        "# embx_item.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "# model01 = MF(embx_user,embx_item,5)\n",
        "\n"
      ],
      "metadata": {
        "id": "JBN4U81W_EMf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model01.userX_embedding.weight"
      ],
      "metadata": {
        "id": "OxQstTCALYJJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model01(torch.tensor([0]), torch.tensor(items[0]))"
      ],
      "metadata": {
        "id": "ImYiM7KaLgL3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model01.item_embed_mat.weight[0]"
      ],
      "metadata": {
        "id": "fX0vajH-STPi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(pred,torch.tensor([diction[0,0]]))"
      ],
      "metadata": {
        "id": "wjtcrNiMWm66"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.Adam(model01.parameters(), lr=0.01, weight_decay=0.0)\n",
        "# loss = F.mse_loss(pred,torch.FloatTensor([diction[0,0]]))\n",
        "# optimizer.zero_grad()\n",
        "# loss.backward()\n",
        "# optimizer.step()"
      ],
      "metadata": {
        "id": "9Ttxl73lW7lv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model01.item_embed_mat.weight[0])\n",
        "# print(model01.userX_embedding.weight)"
      ],
      "metadata": {
        "id": "bCtRM_3cX7iw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8wIADslfG7-"
      },
      "source": [
        "# model = MF(num_users, num_items, emb_size=5) # .cuda() if you have a GPU"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(df_train.movieId.unique()))\n",
        "# print(max(df_train.movieId.values))"
      ],
      "metadata": {
        "id": "DqtdpvnIZCtP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_model_parameters(model1, model2):\n",
        "    # Adds the parameters of model1 to model2\n",
        "\n",
        "    params1 = model1.named_parameters()\n",
        "    params2 = model2.named_parameters()\n",
        "\n",
        "    dict_params2 = dict(params2)\n",
        "\n",
        "    for name1, param1 in params1:\n",
        "        if name1 in dict_params2 and name1 != 'user_embedding.weight':\n",
        "            dict_params2[name1].data.copy_(param1.data + dict_params2[name1].data)\n",
        "\n",
        "    model2.load_state_dict(dict_params2)\n",
        "\n",
        "def sub_model_parameters(model1, model2):\n",
        "    # Subtracts the parameters of model2 with model1\n",
        "\n",
        "    params1 = model1.named_parameters()\n",
        "    params2 = model2.named_parameters()\n",
        "\n",
        "    dict_params2 = dict(params2)\n",
        "\n",
        "    for name1, param1 in params1:\n",
        "        if name1 in dict_params2 and name1 != 'user_embedding.weight':\n",
        "            dict_params2[name1].data.copy_(dict_params2[name1].data - param1.data)\n",
        "\n",
        "    model2.load_state_dict(dict_params2)\n",
        "\n",
        "def divide_model_parameters(model, f):\n",
        "    # Divides model parameters except for the user embeddings with f\n",
        "    params1 = model.named_parameters()\n",
        "    params2 = model.named_parameters()\n",
        "    dict_params2 = dict(params2)\n",
        "    for name1, param1 in params1:\n",
        "        if name1 != 'user_embedding.weight':\n",
        "            dict_params2[name1].data.copy_(param1.data / f)\n",
        "    model.load_state_dict(dict_params2)\n",
        "\n",
        "def zero_model_parameters(model):\n",
        "    # sets all parameters to zero\n",
        "\n",
        "    params1 = model.named_parameters()\n",
        "    params2 = model.named_parameters()\n",
        "    dict_params2 = dict(params2)\n",
        "    for name1, param1 in params1:\n",
        "        if name1 in dict_params2:\n",
        "            dict_params2[name1].data.copy_(param1.data - dict_params2[name1].data)\n",
        "\n",
        "    model.load_state_dict(dict_params2)"
      ],
      "metadata": {
        "id": "H-RAUV3onVp2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "PaEU707c5QQB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYuOM0iWfJH0"
      },
      "source": [
        "def fed_train_client(model_server, df_train,epochs=10, lr=0.1):\n",
        "    \n",
        "    emb_size=5\n",
        "    los=[]\n",
        "    los_usr=[]\n",
        "    user_emb_dict = {}\n",
        "    item_emb_mat_dict = {}\n",
        "\n",
        "    \n",
        "    model_diff = copy.deepcopy(model_server)\n",
        "    zero_model_parameters(model_diff)\n",
        "    # model02(torch.tensor([0]), torch.tensor(items[0]))\n",
        "\n",
        "    \n",
        "    for user_id in range(len(df_train.userId.unique())):\n",
        "        \n",
        "        model02 = copy.deepcopy(model_server)\n",
        "        optimizer = torch.optim.Adam(model02.parameters(), lr=lr, weight_decay=1e-5)\n",
        "        batch = df_train[df_train.userId == user_id]\n",
        "        batch = batch.to_numpy(dtype=int, copy=True)\n",
        "        for e in range(epochs):\n",
        "            for data_point in batch:\n",
        "                # print(data_point)\n",
        "                y_hat = model02(torch.tensor([0]), torch.tensor(data_point[1]))\n",
        "\n",
        "                loss_fn = RMSELoss()\n",
        "                loss = loss_fn(y_hat,torch.FloatTensor([data_point[2]]))\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                los.append(loss.item())\n",
        "            \n",
        "            los_usr.append(np.sqrt(np.sum([x**2 for x in los])/len(batch)))\n",
        "            los.clear()\n",
        "        # running_loss = running_loss/len(data_point)\n",
        "        user_emb_dict[user_id] = copy.deepcopy(model02.userX_embedding.weight)\n",
        "        item_emb_mat_dict[user_id] = copy.deepcopy(model02.item_embed_mat.weight)\n",
        "        \n",
        "        print(\"userId:\", user_id, \"training_loss: \", np.mean(los_usr))\n",
        "        los_usr.clear()\n",
        "\n",
        "        sub_model_parameters(model_server, model02)\n",
        "        add_model_parameters(model02, model_diff)\n",
        "        \n",
        "    # Take the average of the MLP and item vectors\n",
        "    divide_model_parameters(model_diff, (len(df_train.userId.unique())))\n",
        "\n",
        "    # Update the global model by adding the total change\n",
        "    add_model_parameters(model_diff, model_server)\n",
        "  \n",
        "    # test_loss(model, unsqueeze)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fed_eval(model, df_val):\n",
        "    los = []\n",
        "    los_usr = []\n",
        "    for user_id in range(len(df_val.userId.unique())):\n",
        "        batch = df_val[df_val.userId == user_id]\n",
        "        batch = batch.to_numpy(dtype=int, copy=True)\n",
        "        for data_point in batch:\n",
        "            y_hat = model(torch.tensor([0]), torch.tensor(data_point[1]))\n",
        "            # loss = RMSELoss(y_hat,torch.FloatTensor([data_point[2]]))\n",
        "            loss_fn = RMSELoss()\n",
        "            loss = loss_fn(y_hat,torch.FloatTensor([data_point[2]]))\n",
        "            los.append(loss.item())\n",
        "        los_usr.append(np.sqrt(np.sum([x**2 for x in los])/len(batch)))\n",
        "        los.clear()\n",
        "    return np.mean(los_usr)\n"
      ],
      "metadata": {
        "id": "wcWR8tjhuHii"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Server():\n",
        "\n",
        "    from_user = 20\n",
        "    to_user = 40\n",
        "    from_item = 1\n",
        "    to_item = 10000\n",
        "    # embedding_size = int(0.2*(to_user - from_user + 1))\n",
        "    emb_size=20\n",
        "    Max_BatchSize_User = 20\n",
        "    rounds=100\n",
        "    C = 0.4\n",
        "    E = 1\n",
        "    B = 102\n",
        "    T = 196\n",
        "    lr = 0.3\n",
        "    eta = 80\n",
        "    print(\"embedding size is: \",emb_size)\n",
        "    print(\"Max Batch Size is: \",Max_BatchSize_User)\n",
        "\n",
        "    filtered_data = filtering_data(data, from_user, to_user, from_item, to_item)\n",
        "    np.random.seed(3)\n",
        "    msk = np.random.rand(len(filtered_data)) < 0.8\n",
        "    train = filtered_data[msk].copy()\n",
        "    val = filtered_data[~msk].copy()\n",
        "    df_train = encode_data(train)\n",
        "    df_val = encode_data(val, train)\n",
        "\n",
        "    \n",
        "    embx_item = nn.Embedding(len(df_train.movieId.unique()), emb_size)\n",
        "    embx_user = nn.Embedding(1,emb_size)\n",
        "    embx_user.weight.data.uniform_(0, 0.05)\n",
        "    embx_item.weight.data.uniform_(0, 0.05)\n",
        "    model_server = MF(embx_user,embx_item,emb_size)\n",
        "\n",
        "    for t in range(rounds):  # for each round\n",
        "\n",
        "        print(\"Starting round\", t + 1)\n",
        "        # train one round\n",
        "        fed_train_client(model_server, df_train, epochs=10, lr=0.1)\n",
        "\n",
        "        print(\"Evaluating model...\")\n",
        "        computed_loss = fed_eval(model_server, df_val)\n",
        "        print(\"computed_loss:\", computed_loss)\n",
        "        "
      ],
      "metadata": {
        "id": "P4F6H_Y_ticR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Server()"
      ],
      "metadata": {
        "id": "K7lAh348j_jy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bbe3e9-bc3e-49b3-b499-8e050e750e40"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding size is:  20\n",
            "Max Batch Size is:  20\n",
            "Starting round 1\n",
            "userId: 0 training_loss:  4.92512815378913\n",
            "userId: 1 training_loss:  4.652927925351149\n",
            "userId: 2 training_loss:  4.4370720374838335\n",
            "userId: 3 training_loss:  5.897099871002085\n",
            "userId: 4 training_loss:  5.97166563562585\n",
            "userId: 5 training_loss:  2.2148983349319566\n",
            "userId: 6 training_loss:  2.667087924439403\n",
            "userId: 7 training_loss:  5.473252892398774\n",
            "userId: 8 training_loss:  4.071604715421445\n",
            "userId: 9 training_loss:  5.773436557957204\n",
            "userId: 10 training_loss:  2.372393644177599\n",
            "userId: 11 training_loss:  4.295830789072553\n",
            "userId: 12 training_loss:  6.247232464995074\n",
            "userId: 13 training_loss:  5.578323331678989\n",
            "userId: 14 training_loss:  4.430454069807026\n",
            "userId: 15 training_loss:  3.124921327268061\n",
            "userId: 16 training_loss:  3.6030762729772148\n",
            "userId: 17 training_loss:  3.223580670944466\n",
            "userId: 18 training_loss:  5.1797384405974976\n",
            "userId: 19 training_loss:  6.554781231748528\n",
            "userId: 20 training_loss:  6.465405541391519\n",
            "Evaluating model...\n",
            "computed_loss: 3.52185836457474\n",
            "Starting round 2\n",
            "userId: 0 training_loss:  5.541619290400865\n",
            "userId: 1 training_loss:  5.317414857433699\n",
            "userId: 2 training_loss:  3.8449598476323863\n",
            "userId: 3 training_loss:  5.252711966585649\n",
            "userId: 4 training_loss:  4.212994339223992\n",
            "userId: 5 training_loss:  1.774067842366864\n",
            "userId: 6 training_loss:  2.597499523326093\n",
            "userId: 7 training_loss:  4.863720220998156\n",
            "userId: 8 training_loss:  5.736940678212133\n",
            "userId: 9 training_loss:  4.400154460792615\n",
            "userId: 10 training_loss:  2.8383853268369954\n",
            "userId: 11 training_loss:  4.278026684334508\n",
            "userId: 12 training_loss:  4.919301492944234\n",
            "userId: 13 training_loss:  5.9576430442039054\n",
            "userId: 14 training_loss:  4.538061756879587\n",
            "userId: 15 training_loss:  2.91567502876813\n",
            "userId: 16 training_loss:  3.9003161520678296\n",
            "userId: 17 training_loss:  3.034026900922587\n",
            "userId: 18 training_loss:  4.280495718077406\n",
            "userId: 19 training_loss:  5.847871743067814\n",
            "userId: 20 training_loss:  4.678517688949073\n",
            "Evaluating model...\n",
            "computed_loss: 3.4931143599012078\n",
            "Starting round 3\n",
            "userId: 0 training_loss:  5.573453619944705\n",
            "userId: 1 training_loss:  5.205952917745205\n",
            "userId: 2 training_loss:  4.758901826051936\n",
            "userId: 3 training_loss:  5.16187103058987\n",
            "userId: 4 training_loss:  3.898427399610179\n",
            "userId: 5 training_loss:  1.8939456995164299\n",
            "userId: 6 training_loss:  2.5964516154032435\n",
            "userId: 7 training_loss:  5.477017428696516\n",
            "userId: 8 training_loss:  6.742189749165642\n",
            "userId: 9 training_loss:  4.228095469863666\n",
            "userId: 10 training_loss:  2.377399671945832\n",
            "userId: 11 training_loss:  4.018618839724392\n",
            "userId: 12 training_loss:  5.2093344105873545\n",
            "userId: 13 training_loss:  5.847953849821103\n",
            "userId: 14 training_loss:  4.4970826219965065\n",
            "userId: 15 training_loss:  3.0920861099693697\n",
            "userId: 16 training_loss:  4.642835240845061\n",
            "userId: 17 training_loss:  2.818926106670273\n",
            "userId: 18 training_loss:  5.102628808241528\n",
            "userId: 19 training_loss:  5.322204143462821\n",
            "userId: 20 training_loss:  5.103870924574563\n",
            "Evaluating model...\n",
            "computed_loss: 3.3542421367396456\n",
            "Starting round 4\n",
            "userId: 0 training_loss:  5.774828975383265\n",
            "userId: 1 training_loss:  5.314165741300207\n",
            "userId: 2 training_loss:  3.5450615718419867\n",
            "userId: 3 training_loss:  5.585401425215608\n",
            "userId: 4 training_loss:  4.768349867634461\n",
            "userId: 5 training_loss:  1.4707811824017523\n",
            "userId: 6 training_loss:  1.9763491809453815\n",
            "userId: 7 training_loss:  6.713434986995409\n",
            "userId: 8 training_loss:  6.220736745905538\n",
            "userId: 9 training_loss:  4.780837517127506\n",
            "userId: 10 training_loss:  1.89091339175743\n",
            "userId: 11 training_loss:  4.308900944457245\n",
            "userId: 12 training_loss:  5.048207858399343\n",
            "userId: 13 training_loss:  5.797449717921224\n",
            "userId: 14 training_loss:  3.46327258235331\n",
            "userId: 15 training_loss:  2.767356955658654\n",
            "userId: 16 training_loss:  4.132192397176089\n",
            "userId: 17 training_loss:  3.053668247360358\n",
            "userId: 18 training_loss:  4.057980253750184\n",
            "userId: 19 training_loss:  5.120906117899704\n",
            "userId: 20 training_loss:  5.1174811911166085\n",
            "Evaluating model...\n",
            "computed_loss: 3.1313444929143137\n",
            "Starting round 5\n",
            "userId: 0 training_loss:  6.659527176311924\n",
            "userId: 1 training_loss:  5.41406756451869\n",
            "userId: 2 training_loss:  4.0282897000092\n",
            "userId: 3 training_loss:  5.633844247884723\n",
            "userId: 4 training_loss:  4.343259400174729\n",
            "userId: 5 training_loss:  1.4404172782569036\n",
            "userId: 6 training_loss:  1.7800283083352197\n",
            "userId: 7 training_loss:  5.542743216053172\n",
            "userId: 8 training_loss:  6.909506422988104\n",
            "userId: 9 training_loss:  5.095349671712901\n",
            "userId: 10 training_loss:  2.0917549306569225\n",
            "userId: 11 training_loss:  4.11782965685156\n",
            "userId: 12 training_loss:  5.163091251994706\n",
            "userId: 13 training_loss:  6.612418624150732\n",
            "userId: 14 training_loss:  4.055782436934751\n",
            "userId: 15 training_loss:  2.46074554380722\n",
            "userId: 16 training_loss:  3.511602954817765\n",
            "userId: 17 training_loss:  2.5016408268099113\n",
            "userId: 18 training_loss:  4.716568054542184\n",
            "userId: 19 training_loss:  5.606193496033807\n",
            "userId: 20 training_loss:  5.751796552012424\n",
            "Evaluating model...\n",
            "computed_loss: 2.8697557496643062\n",
            "Starting round 6\n",
            "userId: 0 training_loss:  6.212191155024534\n",
            "userId: 1 training_loss:  5.423926583061333\n",
            "userId: 2 training_loss:  3.952946518009143\n",
            "userId: 3 training_loss:  5.366589885051587\n",
            "userId: 4 training_loss:  4.234757260923321\n",
            "userId: 5 training_loss:  1.3397040245714047\n",
            "userId: 6 training_loss:  1.9944625869162198\n",
            "userId: 7 training_loss:  5.982702096551311\n",
            "userId: 8 training_loss:  7.069252234218512\n",
            "userId: 9 training_loss:  5.480459631977942\n",
            "userId: 10 training_loss:  1.712698441294012\n",
            "userId: 11 training_loss:  4.030735912597521\n",
            "userId: 12 training_loss:  5.4825222100987006\n",
            "userId: 13 training_loss:  5.591139130433177\n",
            "userId: 14 training_loss:  5.060005154786827\n",
            "userId: 15 training_loss:  2.5227366671644895\n",
            "userId: 16 training_loss:  3.6821246001176755\n",
            "userId: 17 training_loss:  1.8629728025041061\n",
            "userId: 18 training_loss:  4.0531301789767324\n",
            "userId: 19 training_loss:  5.886204589719812\n",
            "userId: 20 training_loss:  5.536633252471908\n",
            "Evaluating model...\n",
            "computed_loss: 2.858489115171036\n",
            "Starting round 7\n",
            "userId: 0 training_loss:  6.02797522284766\n",
            "userId: 1 training_loss:  5.356980209562784\n",
            "userId: 2 training_loss:  3.59709704999333\n",
            "userId: 3 training_loss:  4.798874759283786\n",
            "userId: 4 training_loss:  4.9218928339001\n",
            "userId: 5 training_loss:  1.3111823772271012\n",
            "userId: 6 training_loss:  1.8029300580781857\n",
            "userId: 7 training_loss:  5.341761148598033\n",
            "userId: 8 training_loss:  5.667226056276997\n",
            "userId: 9 training_loss:  5.591681435025564\n",
            "userId: 10 training_loss:  1.5701384289999383\n",
            "userId: 11 training_loss:  6.084207793846041\n",
            "userId: 12 training_loss:  4.751651423752392\n",
            "userId: 13 training_loss:  6.400630318587217\n",
            "userId: 14 training_loss:  4.420481895019291\n",
            "userId: 15 training_loss:  2.5494375798099744\n",
            "userId: 16 training_loss:  4.4054600352093605\n",
            "userId: 17 training_loss:  2.547943536379818\n",
            "userId: 18 training_loss:  3.9781382514899684\n",
            "userId: 19 training_loss:  5.8517833474157745\n",
            "userId: 20 training_loss:  5.126069271602149\n",
            "Evaluating model...\n",
            "computed_loss: 2.7299855835226103\n",
            "Starting round 8\n",
            "userId: 0 training_loss:  6.378046475429645\n",
            "userId: 1 training_loss:  4.929555831236307\n",
            "userId: 2 training_loss:  3.81031539092847\n",
            "userId: 3 training_loss:  4.497333978557231\n",
            "userId: 4 training_loss:  4.165435008338419\n",
            "userId: 5 training_loss:  1.2707120861070982\n",
            "userId: 6 training_loss:  1.8628942788831027\n",
            "userId: 7 training_loss:  5.14390387680606\n",
            "userId: 8 training_loss:  6.760121713819774\n",
            "userId: 9 training_loss:  3.95592917878702\n",
            "userId: 10 training_loss:  1.5679236182263911\n",
            "userId: 11 training_loss:  3.9164644992062754\n",
            "userId: 12 training_loss:  5.8500474255947825\n",
            "userId: 13 training_loss:  5.300126066698587\n",
            "userId: 14 training_loss:  4.695419234438369\n",
            "userId: 15 training_loss:  2.3720977711663984\n",
            "userId: 16 training_loss:  3.5316439728464517\n",
            "userId: 17 training_loss:  2.265838569275723\n",
            "userId: 18 training_loss:  4.356496270572197\n",
            "userId: 19 training_loss:  4.522612437211511\n",
            "userId: 20 training_loss:  4.999891412757858\n",
            "Evaluating model...\n",
            "computed_loss: 2.470899325243176\n",
            "Starting round 9\n",
            "userId: 0 training_loss:  6.028174306047635\n",
            "userId: 1 training_loss:  4.931100541434643\n",
            "userId: 2 training_loss:  4.1476288021987795\n",
            "userId: 3 training_loss:  5.313651640224175\n",
            "userId: 4 training_loss:  3.9858241284087725\n",
            "userId: 5 training_loss:  1.2636635709502941\n",
            "userId: 6 training_loss:  1.865791791756105\n",
            "userId: 7 training_loss:  4.775689498225017\n",
            "userId: 8 training_loss:  6.249646443606798\n",
            "userId: 9 training_loss:  4.288652034383907\n",
            "userId: 10 training_loss:  1.5631546684580773\n",
            "userId: 11 training_loss:  3.641308284858769\n",
            "userId: 12 training_loss:  5.0129605446122545\n",
            "userId: 13 training_loss:  5.828166996043745\n",
            "userId: 14 training_loss:  4.39321673754876\n",
            "userId: 15 training_loss:  2.3309686696948217\n",
            "userId: 16 training_loss:  3.7027909690400462\n",
            "userId: 17 training_loss:  2.3842423080141657\n",
            "userId: 18 training_loss:  3.295483866434286\n",
            "userId: 19 training_loss:  5.543532344127184\n",
            "userId: 20 training_loss:  5.047738746351813\n",
            "Evaluating model...\n",
            "computed_loss: 2.3544983842372336\n",
            "Starting round 10\n",
            "userId: 0 training_loss:  5.728204317057465\n",
            "userId: 1 training_loss:  5.862786068695574\n",
            "userId: 2 training_loss:  3.461457355876944\n",
            "userId: 3 training_loss:  5.027762575556816\n",
            "userId: 4 training_loss:  4.425456008402037\n",
            "userId: 5 training_loss:  1.097153135257385\n",
            "userId: 6 training_loss:  1.819037408505324\n",
            "userId: 7 training_loss:  5.34811742809387\n",
            "userId: 8 training_loss:  6.298458017046018\n",
            "userId: 9 training_loss:  4.330837597034646\n",
            "userId: 10 training_loss:  1.555618515819472\n",
            "userId: 11 training_loss:  3.344010644073009\n",
            "userId: 12 training_loss:  4.8014788077090005\n",
            "userId: 13 training_loss:  5.055785345464714\n",
            "userId: 14 training_loss:  3.7461266838312155\n",
            "userId: 15 training_loss:  1.9784657332645872\n",
            "userId: 16 training_loss:  3.8822664072185615\n",
            "userId: 17 training_loss:  2.1042263848585794\n",
            "userId: 18 training_loss:  3.5650668366763973\n",
            "userId: 19 training_loss:  4.939789459232591\n",
            "userId: 20 training_loss:  4.826020770556557\n",
            "Evaluating model...\n",
            "computed_loss: 2.2336071970768168\n",
            "Starting round 11\n",
            "userId: 0 training_loss:  6.36929391671423\n",
            "userId: 1 training_loss:  4.982139792873643\n",
            "userId: 2 training_loss:  3.4343123779887343\n",
            "userId: 3 training_loss:  5.372226273786993\n",
            "userId: 4 training_loss:  3.4610098850986164\n",
            "userId: 5 training_loss:  1.052931759393576\n",
            "userId: 6 training_loss:  1.8767687315444452\n",
            "userId: 7 training_loss:  4.804885517522114\n",
            "userId: 8 training_loss:  6.051533718364497\n",
            "userId: 9 training_loss:  3.820733150116367\n",
            "userId: 10 training_loss:  1.5533901095690388\n",
            "userId: 11 training_loss:  4.248170544874674\n",
            "userId: 12 training_loss:  4.245787768478595\n",
            "userId: 13 training_loss:  4.829300449852591\n",
            "userId: 14 training_loss:  3.936157904973407\n",
            "userId: 15 training_loss:  2.4917896916875324\n",
            "userId: 16 training_loss:  3.888009717722368\n",
            "userId: 17 training_loss:  2.38238201326761\n",
            "userId: 18 training_loss:  4.6850316354124555\n",
            "userId: 19 training_loss:  4.578933884335694\n",
            "userId: 20 training_loss:  3.825306886965405\n",
            "Evaluating model...\n",
            "computed_loss: 2.322844140063744\n",
            "Starting round 12\n",
            "userId: 0 training_loss:  6.387476398036734\n",
            "userId: 1 training_loss:  5.795485814762374\n",
            "userId: 2 training_loss:  3.9217651900237955\n",
            "userId: 3 training_loss:  4.854643237210888\n",
            "userId: 4 training_loss:  3.4897731515808443\n",
            "userId: 5 training_loss:  1.13395103034556\n",
            "userId: 6 training_loss:  1.9274247769667832\n",
            "userId: 7 training_loss:  4.824164633115481\n",
            "userId: 8 training_loss:  6.040517983639566\n",
            "userId: 9 training_loss:  5.067343057846956\n",
            "userId: 10 training_loss:  1.3677836924968516\n",
            "userId: 11 training_loss:  3.8332663257505786\n",
            "userId: 12 training_loss:  4.942423041332427\n",
            "userId: 13 training_loss:  5.788807242423174\n",
            "userId: 14 training_loss:  3.2725978777212257\n",
            "userId: 15 training_loss:  2.6547878692369262\n",
            "userId: 16 training_loss:  3.1020424777755684\n",
            "userId: 17 training_loss:  1.8562507460028663\n",
            "userId: 18 training_loss:  4.166506666553159\n",
            "userId: 19 training_loss:  6.032825856129874\n",
            "userId: 20 training_loss:  4.958099749716726\n",
            "Evaluating model...\n",
            "computed_loss: 2.3509971635006575\n",
            "Starting round 13\n",
            "userId: 0 training_loss:  6.271519440799736\n",
            "userId: 1 training_loss:  4.4662385718112585\n",
            "userId: 2 training_loss:  4.037568576497761\n",
            "userId: 3 training_loss:  4.511867829240272\n",
            "userId: 4 training_loss:  4.003263103634277\n",
            "userId: 5 training_loss:  1.0404870441462055\n",
            "userId: 6 training_loss:  1.9265594177444096\n",
            "userId: 7 training_loss:  4.644512576593236\n",
            "userId: 8 training_loss:  5.570324862365444\n",
            "userId: 9 training_loss:  3.338896720590997\n",
            "userId: 10 training_loss:  1.4339770189959737\n",
            "userId: 11 training_loss:  3.366410586504261\n",
            "userId: 12 training_loss:  4.228203502075463\n",
            "userId: 13 training_loss:  5.818732601846177\n",
            "userId: 14 training_loss:  3.537492326040595\n",
            "userId: 15 training_loss:  2.2358962603987753\n",
            "userId: 16 training_loss:  3.8192964190085013\n",
            "userId: 17 training_loss:  2.2318564753344825\n",
            "userId: 18 training_loss:  3.534243334120039\n",
            "userId: 19 training_loss:  5.656774176801911\n",
            "userId: 20 training_loss:  4.581620965524392\n",
            "Evaluating model...\n",
            "computed_loss: 2.257188401080638\n",
            "Starting round 14\n",
            "userId: 0 training_loss:  5.670801588216282\n",
            "userId: 1 training_loss:  4.922163186175838\n",
            "userId: 2 training_loss:  3.702710477922961\n",
            "userId: 3 training_loss:  4.151713118275877\n",
            "userId: 4 training_loss:  4.073299524700146\n",
            "userId: 5 training_loss:  1.072169946241273\n",
            "userId: 6 training_loss:  1.9441959285305785\n",
            "userId: 7 training_loss:  5.934620041956277\n",
            "userId: 8 training_loss:  5.708902926606385\n",
            "userId: 9 training_loss:  4.451243097073699\n",
            "userId: 10 training_loss:  1.5073930144431753\n",
            "userId: 11 training_loss:  4.489641106182195\n",
            "userId: 12 training_loss:  4.451882747372084\n",
            "userId: 13 training_loss:  5.376864353550113\n",
            "userId: 14 training_loss:  3.7002465259841992\n",
            "userId: 15 training_loss:  2.4335602866805774\n",
            "userId: 16 training_loss:  3.0854209688919343\n",
            "userId: 17 training_loss:  2.1540252529805017\n",
            "userId: 18 training_loss:  3.8314382635595727\n",
            "userId: 19 training_loss:  4.714884500517912\n",
            "userId: 20 training_loss:  5.173285691449552\n",
            "Evaluating model...\n",
            "computed_loss: 2.0613402031878887\n",
            "Starting round 15\n",
            "userId: 0 training_loss:  5.355443937969976\n",
            "userId: 1 training_loss:  5.689855723282582\n",
            "userId: 2 training_loss:  3.9155931732537352\n",
            "userId: 3 training_loss:  4.891607956792958\n",
            "userId: 4 training_loss:  4.352478076519782\n",
            "userId: 5 training_loss:  1.0347547562081802\n",
            "userId: 6 training_loss:  1.8059308485625813\n",
            "userId: 7 training_loss:  5.121098291745058\n",
            "userId: 8 training_loss:  6.1870600431926785\n",
            "userId: 9 training_loss:  4.3279127909642545\n",
            "userId: 10 training_loss:  1.4879384019577198\n",
            "userId: 11 training_loss:  3.9648350749628802\n",
            "userId: 12 training_loss:  4.700534354508324\n",
            "userId: 13 training_loss:  5.089127961152692\n",
            "userId: 14 training_loss:  3.2791643560819366\n",
            "userId: 15 training_loss:  2.3137912442230197\n",
            "userId: 16 training_loss:  3.173400889296253\n",
            "userId: 17 training_loss:  2.3754027744346295\n",
            "userId: 18 training_loss:  3.406314099573142\n",
            "userId: 19 training_loss:  5.166262225147662\n",
            "userId: 20 training_loss:  4.419927559762999\n",
            "Evaluating model...\n",
            "computed_loss: 2.0365523506824204\n",
            "Starting round 16\n",
            "userId: 0 training_loss:  5.536811130784242\n",
            "userId: 1 training_loss:  4.829887311569739\n",
            "userId: 2 training_loss:  3.494091047348924\n",
            "userId: 3 training_loss:  4.241639814147886\n",
            "userId: 4 training_loss:  3.9156604490723472\n",
            "userId: 5 training_loss:  1.1677711174502885\n",
            "userId: 6 training_loss:  1.8683247110588475\n",
            "userId: 7 training_loss:  4.562881477753178\n",
            "userId: 8 training_loss:  6.2030292704745955\n",
            "userId: 9 training_loss:  3.1500019968657305\n",
            "userId: 10 training_loss:  1.462415516955784\n",
            "userId: 11 training_loss:  3.3033657124754137\n",
            "userId: 12 training_loss:  4.689172501639076\n",
            "userId: 13 training_loss:  5.260684425049538\n",
            "userId: 14 training_loss:  4.3732566950823415\n",
            "userId: 15 training_loss:  2.3951576655694895\n",
            "userId: 16 training_loss:  3.2963145418126745\n",
            "userId: 17 training_loss:  2.2017165480389385\n",
            "userId: 18 training_loss:  3.194597025033243\n",
            "userId: 19 training_loss:  4.274521522525811\n",
            "userId: 20 training_loss:  3.606349125154683\n",
            "Evaluating model...\n",
            "computed_loss: 1.9387528683749533\n",
            "Starting round 17\n",
            "userId: 0 training_loss:  5.04849883323838\n",
            "userId: 1 training_loss:  4.834801413655788\n",
            "userId: 2 training_loss:  3.7146636446098\n",
            "userId: 3 training_loss:  4.675536514928283\n",
            "userId: 4 training_loss:  4.068679922329365\n",
            "userId: 5 training_loss:  0.9496313757999015\n",
            "userId: 6 training_loss:  1.7083331179719736\n",
            "userId: 7 training_loss:  4.529116541619735\n",
            "userId: 8 training_loss:  5.678608126866584\n",
            "userId: 9 training_loss:  3.5245290820357646\n",
            "userId: 10 training_loss:  1.4197804444704611\n",
            "userId: 11 training_loss:  3.0583424512654376\n",
            "userId: 12 training_loss:  4.865051780042633\n",
            "userId: 13 training_loss:  4.569500088313655\n",
            "userId: 14 training_loss:  4.028026822225584\n",
            "userId: 15 training_loss:  2.11384519838167\n",
            "userId: 16 training_loss:  3.570866643735621\n",
            "userId: 17 training_loss:  2.3297656436077396\n",
            "userId: 18 training_loss:  3.380106761492685\n",
            "userId: 19 training_loss:  3.9938225319503955\n",
            "userId: 20 training_loss:  4.601764482364186\n",
            "Evaluating model...\n",
            "computed_loss: 1.9261602792860568\n",
            "Starting round 18\n",
            "userId: 0 training_loss:  5.6539581671863886\n",
            "userId: 1 training_loss:  4.825461046943579\n",
            "userId: 2 training_loss:  2.9788638489653216\n",
            "userId: 3 training_loss:  5.196374422514982\n",
            "userId: 4 training_loss:  3.5127577812739057\n",
            "userId: 5 training_loss:  1.099615249082337\n",
            "userId: 6 training_loss:  1.7946006055836208\n",
            "userId: 7 training_loss:  4.5588084575371415\n",
            "userId: 8 training_loss:  5.918365934505667\n",
            "userId: 9 training_loss:  3.0546651112797893\n",
            "userId: 10 training_loss:  1.4425991263492872\n",
            "userId: 11 training_loss:  3.852915880356643\n",
            "userId: 12 training_loss:  4.166574231056383\n",
            "userId: 13 training_loss:  5.064050336400263\n",
            "userId: 14 training_loss:  3.1882313436271863\n",
            "userId: 15 training_loss:  2.2415852453263967\n",
            "userId: 16 training_loss:  3.2786833877915056\n",
            "userId: 17 training_loss:  2.456615709696301\n",
            "userId: 18 training_loss:  3.5923512829980444\n",
            "userId: 19 training_loss:  3.615452766221195\n",
            "userId: 20 training_loss:  4.902412647808764\n",
            "Evaluating model...\n",
            "computed_loss: 1.8383386038372151\n",
            "Starting round 19\n",
            "userId: 0 training_loss:  5.179679605999592\n",
            "userId: 1 training_loss:  4.865802255727312\n",
            "userId: 2 training_loss:  4.474388095790739\n",
            "userId: 3 training_loss:  4.246674294678563\n",
            "userId: 4 training_loss:  3.384876439340605\n",
            "userId: 5 training_loss:  1.0862503799283638\n",
            "userId: 6 training_loss:  1.6956511853561982\n",
            "userId: 7 training_loss:  3.9007042634533065\n",
            "userId: 8 training_loss:  5.894349560693832\n",
            "userId: 9 training_loss:  3.3427273533866497\n",
            "userId: 10 training_loss:  1.3010263598985525\n",
            "userId: 11 training_loss:  3.6607924815605366\n",
            "userId: 12 training_loss:  3.9215162848297873\n",
            "userId: 13 training_loss:  4.999208192772057\n",
            "userId: 14 training_loss:  3.4453939980387434\n",
            "userId: 15 training_loss:  2.3112373062856477\n",
            "userId: 16 training_loss:  2.79050045447614\n",
            "userId: 17 training_loss:  2.2372441717868696\n",
            "userId: 18 training_loss:  4.425004419103962\n",
            "userId: 19 training_loss:  3.9837581858369027\n",
            "userId: 20 training_loss:  4.805826809024838\n",
            "Evaluating model...\n",
            "computed_loss: 1.8609592639788928\n",
            "Starting round 20\n",
            "userId: 0 training_loss:  6.299720797129542\n",
            "userId: 1 training_loss:  4.302261905085734\n",
            "userId: 2 training_loss:  3.6654789295776675\n",
            "userId: 3 training_loss:  4.576782708781363\n",
            "userId: 4 training_loss:  3.555402121519658\n",
            "userId: 5 training_loss:  1.0443021071226029\n",
            "userId: 6 training_loss:  1.6297066227468804\n",
            "userId: 7 training_loss:  4.04211691796306\n",
            "userId: 8 training_loss:  5.686940538512651\n",
            "userId: 9 training_loss:  3.372134952484676\n",
            "userId: 10 training_loss:  1.34819473466577\n",
            "userId: 11 training_loss:  3.839495328856816\n",
            "userId: 12 training_loss:  4.838289228073738\n",
            "userId: 13 training_loss:  5.075586629766185\n",
            "userId: 14 training_loss:  3.9235844423611774\n",
            "userId: 15 training_loss:  2.3008782431505397\n",
            "userId: 16 training_loss:  3.78107961697827\n",
            "userId: 17 training_loss:  2.060586456174134\n",
            "userId: 18 training_loss:  3.269236399671289\n",
            "userId: 19 training_loss:  3.8890241603967697\n",
            "userId: 20 training_loss:  4.179918387024837\n",
            "Evaluating model...\n",
            "computed_loss: 1.8349312091129841\n",
            "Starting round 21\n",
            "userId: 0 training_loss:  5.861632036682378\n",
            "userId: 1 training_loss:  4.701420430344336\n",
            "userId: 2 training_loss:  3.3282395564406584\n",
            "userId: 3 training_loss:  4.122361387037108\n",
            "userId: 4 training_loss:  4.400444526735349\n",
            "userId: 5 training_loss:  1.1350347161356784\n",
            "userId: 6 training_loss:  1.6815926118120808\n",
            "userId: 7 training_loss:  4.389755737613194\n",
            "userId: 8 training_loss:  7.316523525577727\n",
            "userId: 9 training_loss:  3.728876344381816\n",
            "userId: 10 training_loss:  1.2410750350305402\n",
            "userId: 11 training_loss:  3.334667283586081\n",
            "userId: 12 training_loss:  4.858766613640623\n",
            "userId: 13 training_loss:  5.202596596983758\n",
            "userId: 14 training_loss:  3.0157135689706056\n",
            "userId: 15 training_loss:  2.3447649358672438\n",
            "userId: 16 training_loss:  3.381136157181841\n",
            "userId: 17 training_loss:  2.457139098519795\n",
            "userId: 18 training_loss:  3.476328268156415\n",
            "userId: 19 training_loss:  4.406785977706059\n",
            "userId: 20 training_loss:  4.243740805939952\n",
            "Evaluating model...\n",
            "computed_loss: 1.7915496594993625\n",
            "Starting round 22\n",
            "userId: 0 training_loss:  5.840691423408249\n",
            "userId: 1 training_loss:  5.1275254062648035\n",
            "userId: 2 training_loss:  3.3297706364499775\n",
            "userId: 3 training_loss:  4.583764005155027\n",
            "userId: 4 training_loss:  3.3089931400952173\n",
            "userId: 5 training_loss:  0.9296894064354551\n",
            "userId: 6 training_loss:  1.7803329416426767\n",
            "userId: 7 training_loss:  4.585088080720415\n",
            "userId: 8 training_loss:  5.936984514548811\n",
            "userId: 9 training_loss:  3.3545966296865593\n",
            "userId: 10 training_loss:  1.3038052208508972\n",
            "userId: 11 training_loss:  3.4369149681529443\n",
            "userId: 12 training_loss:  3.4938074904083267\n",
            "userId: 13 training_loss:  5.737653356090304\n",
            "userId: 14 training_loss:  3.5743123100375613\n",
            "userId: 15 training_loss:  2.252346322305475\n",
            "userId: 16 training_loss:  3.2354207175748106\n",
            "userId: 17 training_loss:  2.3018361534825553\n",
            "userId: 18 training_loss:  3.47856156576625\n",
            "userId: 19 training_loss:  4.8290535241406705\n",
            "userId: 20 training_loss:  4.427343000146104\n",
            "Evaluating model...\n",
            "computed_loss: 1.898579344662704\n",
            "Starting round 23\n",
            "userId: 0 training_loss:  5.3465486622833165\n",
            "userId: 1 training_loss:  4.436504111051886\n",
            "userId: 2 training_loss:  3.2052958243302854\n",
            "userId: 3 training_loss:  4.404281346145352\n",
            "userId: 4 training_loss:  3.5329788370094013\n",
            "userId: 5 training_loss:  1.0922313916589261\n",
            "userId: 6 training_loss:  1.785757377747761\n",
            "userId: 7 training_loss:  4.971360261655714\n",
            "userId: 8 training_loss:  6.17171516164689\n",
            "userId: 9 training_loss:  3.3577662902060426\n",
            "userId: 10 training_loss:  1.2617591390818759\n",
            "userId: 11 training_loss:  3.5228416451875417\n",
            "userId: 12 training_loss:  4.845628759773362\n",
            "userId: 13 training_loss:  5.05141463819497\n",
            "userId: 14 training_loss:  3.4586151777926673\n",
            "userId: 15 training_loss:  1.8597196724132636\n",
            "userId: 16 training_loss:  2.681411051850813\n",
            "userId: 17 training_loss:  2.0466928177908055\n",
            "userId: 18 training_loss:  4.169899649322818\n",
            "userId: 19 training_loss:  4.5472584680368735\n",
            "userId: 20 training_loss:  4.046617675666945\n",
            "Evaluating model...\n",
            "computed_loss: 1.6016700560784942\n",
            "Starting round 24\n",
            "userId: 0 training_loss:  5.307763593386814\n",
            "userId: 1 training_loss:  4.454017896133896\n",
            "userId: 2 training_loss:  4.305156937687181\n",
            "userId: 3 training_loss:  4.784495506804171\n",
            "userId: 4 training_loss:  4.607228813361624\n",
            "userId: 5 training_loss:  0.9184683238357781\n",
            "userId: 6 training_loss:  1.9990357653183064\n",
            "userId: 7 training_loss:  3.8163955048124847\n",
            "userId: 8 training_loss:  5.599733410149619\n",
            "userId: 9 training_loss:  4.088542047791852\n",
            "userId: 10 training_loss:  1.2986855476850745\n",
            "userId: 11 training_loss:  2.8440872386605776\n",
            "userId: 12 training_loss:  4.055117459506344\n",
            "userId: 13 training_loss:  4.444657541087828\n",
            "userId: 14 training_loss:  3.331477283194341\n",
            "userId: 15 training_loss:  2.2611372493806483\n",
            "userId: 16 training_loss:  4.24072350649803\n",
            "userId: 17 training_loss:  2.036573298576818\n",
            "userId: 18 training_loss:  3.21510950872702\n",
            "userId: 19 training_loss:  5.775363984326617\n",
            "userId: 20 training_loss:  4.0505583853023115\n",
            "Evaluating model...\n",
            "computed_loss: 1.856315435857438\n",
            "Starting round 25\n",
            "userId: 0 training_loss:  5.37490195556329\n",
            "userId: 1 training_loss:  5.137275280940149\n",
            "userId: 2 training_loss:  3.1191147595948516\n",
            "userId: 3 training_loss:  4.337494723957168\n",
            "userId: 4 training_loss:  3.641966050594502\n",
            "userId: 5 training_loss:  1.0666878012785208\n",
            "userId: 6 training_loss:  1.7611181682222743\n",
            "userId: 7 training_loss:  4.262380678779619\n",
            "userId: 8 training_loss:  5.9031708903694335\n",
            "userId: 9 training_loss:  3.2826270210217117\n",
            "userId: 10 training_loss:  1.338230156978767\n",
            "userId: 11 training_loss:  3.678283200742989\n",
            "userId: 12 training_loss:  3.8797974793746244\n",
            "userId: 13 training_loss:  4.517311790498418\n",
            "userId: 14 training_loss:  3.5332885411126016\n",
            "userId: 15 training_loss:  2.6402370644529003\n",
            "userId: 16 training_loss:  2.85017563822459\n",
            "userId: 17 training_loss:  1.9332056465321141\n",
            "userId: 18 training_loss:  4.0210896040775275\n",
            "userId: 19 training_loss:  4.078318368236548\n",
            "userId: 20 training_loss:  5.1068711046872775\n",
            "Evaluating model...\n",
            "computed_loss: 1.7459105348567387\n",
            "Starting round 26\n",
            "userId: 0 training_loss:  4.909001058717886\n",
            "userId: 1 training_loss:  4.552680904985353\n",
            "userId: 2 training_loss:  3.051232444286372\n",
            "userId: 3 training_loss:  3.715904397892884\n",
            "userId: 4 training_loss:  3.567168052754176\n",
            "userId: 5 training_loss:  1.0339597025674958\n",
            "userId: 6 training_loss:  1.602156397870783\n",
            "userId: 7 training_loss:  3.982589657658756\n",
            "userId: 8 training_loss:  5.566697865549569\n",
            "userId: 9 training_loss:  2.98876866459967\n",
            "userId: 10 training_loss:  1.3375690603775854\n",
            "userId: 11 training_loss:  3.2026000286782774\n",
            "userId: 12 training_loss:  4.04620680758533\n",
            "userId: 13 training_loss:  4.589696849676884\n",
            "userId: 14 training_loss:  3.8179302957880976\n",
            "userId: 15 training_loss:  2.2309648657614067\n",
            "userId: 16 training_loss:  3.206156019833684\n",
            "userId: 17 training_loss:  2.2274796658678566\n",
            "userId: 18 training_loss:  3.9501160213391673\n",
            "userId: 19 training_loss:  4.37496544028936\n",
            "userId: 20 training_loss:  3.9306501866577612\n",
            "Evaluating model...\n",
            "computed_loss: 1.528208745311285\n",
            "Starting round 27\n",
            "userId: 0 training_loss:  4.86911934234349\n",
            "userId: 1 training_loss:  4.530590832418904\n",
            "userId: 2 training_loss:  3.700671673779145\n",
            "userId: 3 training_loss:  4.089493131862123\n",
            "userId: 4 training_loss:  3.530468180591529\n",
            "userId: 5 training_loss:  1.038432978698252\n",
            "userId: 6 training_loss:  1.4952893676940744\n",
            "userId: 7 training_loss:  4.3419006271127625\n",
            "userId: 8 training_loss:  5.848136779531425\n",
            "userId: 9 training_loss:  3.1145470417589416\n",
            "userId: 10 training_loss:  1.3667864925291826\n",
            "userId: 11 training_loss:  2.7825418963504895\n",
            "userId: 12 training_loss:  3.9514634111813662\n",
            "userId: 13 training_loss:  4.428150902914932\n",
            "userId: 14 training_loss:  3.5915549128080984\n",
            "userId: 15 training_loss:  2.2832754292835107\n",
            "userId: 16 training_loss:  2.951789120410538\n",
            "userId: 17 training_loss:  2.151489245272659\n",
            "userId: 18 training_loss:  3.5603800859325845\n",
            "userId: 19 training_loss:  3.66831360737885\n",
            "userId: 20 training_loss:  4.354352451022487\n",
            "Evaluating model...\n",
            "computed_loss: 1.518038582382005\n",
            "Starting round 28\n",
            "userId: 0 training_loss:  5.223088497169654\n",
            "userId: 1 training_loss:  4.909108809952798\n",
            "userId: 2 training_loss:  3.2906966420149866\n",
            "userId: 3 training_loss:  4.422477700020051\n",
            "userId: 4 training_loss:  2.981190398247775\n",
            "userId: 5 training_loss:  0.9185465032278322\n",
            "userId: 6 training_loss:  1.601592659567979\n",
            "userId: 7 training_loss:  4.2948167644189486\n",
            "userId: 8 training_loss:  5.920949605918385\n",
            "userId: 9 training_loss:  3.3015454186549826\n",
            "userId: 10 training_loss:  1.2152223897799823\n",
            "userId: 11 training_loss:  2.688679262046803\n",
            "userId: 12 training_loss:  4.839005265310172\n",
            "userId: 13 training_loss:  4.970991563025407\n",
            "userId: 14 training_loss:  4.176659296959061\n",
            "userId: 15 training_loss:  2.477936326724586\n",
            "userId: 16 training_loss:  3.6932288046727573\n",
            "userId: 17 training_loss:  2.0401731229026634\n",
            "userId: 18 training_loss:  3.377614456098209\n",
            "userId: 19 training_loss:  4.23311798736823\n",
            "userId: 20 training_loss:  4.491894377102101\n",
            "Evaluating model...\n",
            "computed_loss: 1.6230471948149972\n",
            "Starting round 29\n",
            "userId: 0 training_loss:  5.664305487574648\n",
            "userId: 1 training_loss:  5.074891262736544\n",
            "userId: 2 training_loss:  3.6574490309354055\n",
            "userId: 3 training_loss:  3.8472776816524155\n",
            "userId: 4 training_loss:  3.0834143198447976\n",
            "userId: 5 training_loss:  0.9715431841739012\n",
            "userId: 6 training_loss:  1.7140413575599542\n",
            "userId: 7 training_loss:  4.960196840141281\n",
            "userId: 8 training_loss:  5.954924385762938\n",
            "userId: 9 training_loss:  2.9357885150451333\n",
            "userId: 10 training_loss:  1.2913960913640372\n",
            "userId: 11 training_loss:  4.131067618727455\n",
            "userId: 12 training_loss:  3.750345234842606\n",
            "userId: 13 training_loss:  4.648051514506016\n",
            "userId: 14 training_loss:  4.68871088631654\n",
            "userId: 15 training_loss:  2.202374291252151\n",
            "userId: 16 training_loss:  3.844030235054658\n",
            "userId: 17 training_loss:  2.459812558944233\n",
            "userId: 18 training_loss:  4.016770001331402\n",
            "userId: 19 training_loss:  4.194263665655452\n",
            "userId: 20 training_loss:  4.273709376955137\n",
            "Evaluating model...\n",
            "computed_loss: 1.5720903534012545\n",
            "Starting round 30\n",
            "userId: 0 training_loss:  5.711485768553635\n",
            "userId: 1 training_loss:  4.693949606903133\n",
            "userId: 2 training_loss:  3.782433588270932\n",
            "userId: 3 training_loss:  3.979453039507496\n",
            "userId: 4 training_loss:  3.5512001815587224\n",
            "userId: 5 training_loss:  0.9602313905540416\n",
            "userId: 6 training_loss:  1.7710995466711936\n",
            "userId: 7 training_loss:  4.253968118221751\n",
            "userId: 8 training_loss:  5.744151954825644\n",
            "userId: 9 training_loss:  2.5746376298272144\n",
            "userId: 10 training_loss:  1.2470878752321888\n",
            "userId: 11 training_loss:  3.632008543380844\n",
            "userId: 12 training_loss:  3.4242041065880358\n",
            "userId: 13 training_loss:  4.318306883243955\n",
            "userId: 14 training_loss:  3.4503995002748065\n",
            "userId: 15 training_loss:  2.333435459807015\n",
            "userId: 16 training_loss:  2.638859395172296\n",
            "userId: 17 training_loss:  2.13807806505322\n",
            "userId: 18 training_loss:  3.2644604894809524\n",
            "userId: 19 training_loss:  3.8333135024985596\n",
            "userId: 20 training_loss:  4.169691764408104\n",
            "Evaluating model...\n",
            "computed_loss: 1.8156892284573805\n",
            "Starting round 31\n",
            "userId: 0 training_loss:  5.217271045920989\n",
            "userId: 1 training_loss:  4.394792210822873\n",
            "userId: 2 training_loss:  2.7312828083439347\n",
            "userId: 3 training_loss:  3.8418954289463727\n",
            "userId: 4 training_loss:  3.2625020038909023\n",
            "userId: 5 training_loss:  1.1883478841481145\n",
            "userId: 6 training_loss:  1.5951138188986038\n",
            "userId: 7 training_loss:  3.965319146506205\n",
            "userId: 8 training_loss:  5.749709684192061\n",
            "userId: 9 training_loss:  3.2422825871510232\n",
            "userId: 10 training_loss:  1.4037197766884446\n",
            "userId: 11 training_loss:  3.3111831321200382\n",
            "userId: 12 training_loss:  4.641788004824777\n",
            "userId: 13 training_loss:  4.424227791500821\n",
            "userId: 14 training_loss:  3.303364584533873\n",
            "userId: 15 training_loss:  2.2348375414063772\n",
            "userId: 16 training_loss:  2.9990527562609746\n",
            "userId: 17 training_loss:  1.996598808831174\n",
            "userId: 18 training_loss:  3.554217504523872\n",
            "userId: 19 training_loss:  3.7576741307275796\n",
            "userId: 20 training_loss:  5.117488267018332\n",
            "Evaluating model...\n",
            "computed_loss: 1.7931125916274102\n",
            "Starting round 32\n",
            "userId: 0 training_loss:  4.840776354499068\n",
            "userId: 1 training_loss:  5.180676050461248\n",
            "userId: 2 training_loss:  2.7485567361970626\n",
            "userId: 3 training_loss:  4.061643645956993\n",
            "userId: 4 training_loss:  4.306843114647551\n",
            "userId: 5 training_loss:  1.0754361865000657\n",
            "userId: 6 training_loss:  2.0774474267809167\n",
            "userId: 7 training_loss:  4.293037960875757\n",
            "userId: 8 training_loss:  6.306672534239013\n",
            "userId: 9 training_loss:  3.134979320340107\n",
            "userId: 10 training_loss:  1.2367852819918963\n",
            "userId: 11 training_loss:  4.298051330288812\n",
            "userId: 12 training_loss:  4.232325599453522\n",
            "userId: 13 training_loss:  4.273711626618583\n",
            "userId: 14 training_loss:  3.9992645807594926\n",
            "userId: 15 training_loss:  2.097379782882266\n",
            "userId: 16 training_loss:  2.9745612149245213\n",
            "userId: 17 training_loss:  2.4528020203399903\n",
            "userId: 18 training_loss:  3.0782460065507706\n",
            "userId: 19 training_loss:  4.26183099729151\n",
            "userId: 20 training_loss:  3.749285470952187\n",
            "Evaluating model...\n",
            "computed_loss: 1.4482650861832487\n",
            "Starting round 33\n",
            "userId: 0 training_loss:  5.115041512844871\n",
            "userId: 1 training_loss:  4.425219918175892\n",
            "userId: 2 training_loss:  3.677650669749253\n",
            "userId: 3 training_loss:  4.074695755844654\n",
            "userId: 4 training_loss:  3.387669692117357\n",
            "userId: 5 training_loss:  1.0837318922069519\n",
            "userId: 6 training_loss:  1.4975448242979548\n",
            "userId: 7 training_loss:  4.244965250867482\n",
            "userId: 8 training_loss:  6.648550360343504\n",
            "userId: 9 training_loss:  3.516249949433319\n",
            "userId: 10 training_loss:  1.242416540776627\n",
            "userId: 11 training_loss:  4.135303635551791\n",
            "userId: 12 training_loss:  4.050417654020296\n",
            "userId: 13 training_loss:  4.920819883131378\n",
            "userId: 14 training_loss:  3.2761276558150847\n",
            "userId: 15 training_loss:  2.025102689238291\n",
            "userId: 16 training_loss:  2.705498716238794\n",
            "userId: 17 training_loss:  2.25196612909134\n",
            "userId: 18 training_loss:  3.5480449688246205\n",
            "userId: 19 training_loss:  3.3596918297655867\n",
            "userId: 20 training_loss:  4.105852355674081\n",
            "Evaluating model...\n",
            "computed_loss: 1.6088495545930104\n",
            "Starting round 34\n",
            "userId: 0 training_loss:  5.663367834548064\n",
            "userId: 1 training_loss:  4.752879409406286\n",
            "userId: 2 training_loss:  3.4532230038353715\n",
            "userId: 3 training_loss:  4.739905932378084\n",
            "userId: 4 training_loss:  3.5320590660999223\n",
            "userId: 5 training_loss:  1.127424657636303\n",
            "userId: 6 training_loss:  1.7449343687905938\n",
            "userId: 7 training_loss:  3.7135801296431667\n",
            "userId: 8 training_loss:  5.46966974343147\n",
            "userId: 9 training_loss:  3.0830383277338265\n",
            "userId: 10 training_loss:  1.3435041837692396\n",
            "userId: 11 training_loss:  2.71781044881496\n",
            "userId: 12 training_loss:  3.999440539888122\n",
            "userId: 13 training_loss:  4.550156132173227\n",
            "userId: 14 training_loss:  3.6966593284585954\n",
            "userId: 15 training_loss:  2.1071075234644177\n",
            "userId: 16 training_loss:  3.23272305949948\n",
            "userId: 17 training_loss:  2.123357138314481\n",
            "userId: 18 training_loss:  3.5322100436230017\n",
            "userId: 19 training_loss:  3.8965814091777333\n",
            "userId: 20 training_loss:  4.111717356954516\n",
            "Evaluating model...\n",
            "computed_loss: 1.6221363165241904\n",
            "Starting round 35\n",
            "userId: 0 training_loss:  5.569535603557145\n",
            "userId: 1 training_loss:  5.181935557695652\n",
            "userId: 2 training_loss:  2.784167964174139\n",
            "userId: 3 training_loss:  3.5855426746867662\n",
            "userId: 4 training_loss:  3.6195688453726396\n",
            "userId: 5 training_loss:  1.067344738065923\n",
            "userId: 6 training_loss:  1.7971187018617076\n",
            "userId: 7 training_loss:  4.5977910642320445\n",
            "userId: 8 training_loss:  5.670364346040134\n",
            "userId: 9 training_loss:  3.091708799163402\n",
            "userId: 10 training_loss:  1.3030750813327805\n",
            "userId: 11 training_loss:  4.463696058395182\n",
            "userId: 12 training_loss:  3.844439587644517\n",
            "userId: 13 training_loss:  4.199319854370788\n",
            "userId: 14 training_loss:  3.797708178806211\n",
            "userId: 15 training_loss:  2.399921468343918\n",
            "userId: 16 training_loss:  3.7600941131667347\n",
            "userId: 17 training_loss:  2.3402342307962343\n",
            "userId: 18 training_loss:  3.2671941457239235\n",
            "userId: 19 training_loss:  3.672450089181382\n",
            "userId: 20 training_loss:  3.661052656160179\n",
            "Evaluating model...\n",
            "computed_loss: 1.5309758653514378\n",
            "Starting round 36\n",
            "userId: 0 training_loss:  5.244286784752952\n",
            "userId: 1 training_loss:  4.690467370754373\n",
            "userId: 2 training_loss:  3.620796682637299\n",
            "userId: 3 training_loss:  3.6834015782127922\n",
            "userId: 4 training_loss:  3.460375601760623\n",
            "userId: 5 training_loss:  1.2303877877255431\n",
            "userId: 6 training_loss:  1.5461899342958043\n",
            "userId: 7 training_loss:  4.313045701101985\n",
            "userId: 8 training_loss:  5.604347525944301\n",
            "userId: 9 training_loss:  3.1276324540970037\n",
            "userId: 10 training_loss:  1.1833202605392266\n",
            "userId: 11 training_loss:  3.8168907686069806\n",
            "userId: 12 training_loss:  3.359188643428986\n",
            "userId: 13 training_loss:  4.278101057585641\n",
            "userId: 14 training_loss:  3.4299002710474573\n",
            "userId: 15 training_loss:  1.9842424450501093\n",
            "userId: 16 training_loss:  2.7578607129512025\n",
            "userId: 17 training_loss:  2.1782234247279995\n",
            "userId: 18 training_loss:  3.3319310594602323\n",
            "userId: 19 training_loss:  3.4803262646896322\n",
            "userId: 20 training_loss:  4.351175139575864\n",
            "Evaluating model...\n",
            "computed_loss: 1.751529067699904\n",
            "Starting round 37\n",
            "userId: 0 training_loss:  4.995412522330177\n",
            "userId: 1 training_loss:  4.437192815056585\n",
            "userId: 2 training_loss:  3.658482313125704\n",
            "userId: 3 training_loss:  4.12066003482288\n",
            "userId: 4 training_loss:  3.535717815951714\n",
            "userId: 5 training_loss:  1.1816593761863943\n",
            "userId: 6 training_loss:  1.6383289425313259\n",
            "userId: 7 training_loss:  4.329608270185349\n",
            "userId: 8 training_loss:  5.428100781702388\n",
            "userId: 9 training_loss:  3.9028194099364177\n",
            "userId: 10 training_loss:  1.4402152861932476\n",
            "userId: 11 training_loss:  3.1802733524449134\n",
            "userId: 12 training_loss:  4.3656034530007375\n",
            "userId: 13 training_loss:  4.515615149972788\n",
            "userId: 14 training_loss:  2.975046998282034\n",
            "userId: 15 training_loss:  2.4221880381334158\n",
            "userId: 16 training_loss:  2.903660334303871\n",
            "userId: 17 training_loss:  2.0407737042473024\n",
            "userId: 18 training_loss:  3.0149572978116495\n",
            "userId: 19 training_loss:  3.502200465946005\n",
            "userId: 20 training_loss:  3.875690452917776\n",
            "Evaluating model...\n",
            "computed_loss: 1.5795474245143406\n",
            "Starting round 38\n",
            "userId: 0 training_loss:  5.417297674700281\n",
            "userId: 1 training_loss:  4.429074431476244\n",
            "userId: 2 training_loss:  3.187068020102136\n",
            "userId: 3 training_loss:  4.141487828706206\n",
            "userId: 4 training_loss:  3.0536488322930455\n",
            "userId: 5 training_loss:  1.2221535580033402\n",
            "userId: 6 training_loss:  1.4924787052368491\n",
            "userId: 7 training_loss:  4.269969141350637\n",
            "userId: 8 training_loss:  6.273349528116816\n",
            "userId: 9 training_loss:  3.2447523404209706\n",
            "userId: 10 training_loss:  1.3933010011186504\n",
            "userId: 11 training_loss:  4.645422390885476\n",
            "userId: 12 training_loss:  4.198167800631775\n",
            "userId: 13 training_loss:  5.001450764846043\n",
            "userId: 14 training_loss:  3.1585775962021794\n",
            "userId: 15 training_loss:  2.3573652761786006\n",
            "userId: 16 training_loss:  2.797456418227979\n",
            "userId: 17 training_loss:  2.002654431395807\n",
            "userId: 18 training_loss:  3.2550821314824416\n",
            "userId: 19 training_loss:  3.9965873459649743\n",
            "userId: 20 training_loss:  3.862592010357929\n",
            "Evaluating model...\n",
            "computed_loss: 1.7089684669060257\n",
            "Starting round 39\n",
            "userId: 0 training_loss:  5.619137170921782\n",
            "userId: 1 training_loss:  4.549422871110851\n",
            "userId: 2 training_loss:  3.0183537008899797\n",
            "userId: 3 training_loss:  3.8197158986358977\n",
            "userId: 4 training_loss:  3.427325284587622\n",
            "userId: 5 training_loss:  1.1604368266857965\n",
            "userId: 6 training_loss:  1.6123670657285563\n",
            "userId: 7 training_loss:  4.171108482112674\n",
            "userId: 8 training_loss:  6.139435973180065\n",
            "userId: 9 training_loss:  4.9261758547024135\n",
            "userId: 10 training_loss:  1.4376981860357427\n",
            "userId: 11 training_loss:  3.4383893986328298\n",
            "userId: 12 training_loss:  4.624041068418731\n",
            "userId: 13 training_loss:  4.531834746041531\n",
            "userId: 14 training_loss:  2.897256780336524\n",
            "userId: 15 training_loss:  2.1520275402730222\n",
            "userId: 16 training_loss:  2.8620373641849843\n",
            "userId: 17 training_loss:  2.2912959607902095\n",
            "userId: 18 training_loss:  3.2097826068022597\n",
            "userId: 19 training_loss:  3.9880958462032035\n",
            "userId: 20 training_loss:  3.723179632468958\n",
            "Evaluating model...\n",
            "computed_loss: 1.5870251834434188\n",
            "Starting round 40\n",
            "userId: 0 training_loss:  6.185128056491347\n",
            "userId: 1 training_loss:  4.223383064025221\n",
            "userId: 2 training_loss:  2.8000690343123664\n",
            "userId: 3 training_loss:  3.9605010696305483\n",
            "userId: 4 training_loss:  2.7438784045278615\n",
            "userId: 5 training_loss:  1.0502200639724508\n",
            "userId: 6 training_loss:  1.6797853999445302\n",
            "userId: 7 training_loss:  4.162171586771729\n",
            "userId: 8 training_loss:  6.45697175649327\n",
            "userId: 9 training_loss:  3.2354327230350384\n",
            "userId: 10 training_loss:  1.2648914552610182\n",
            "userId: 11 training_loss:  3.062984406462233\n",
            "userId: 12 training_loss:  3.4330308162544076\n",
            "userId: 13 training_loss:  4.295218045207768\n",
            "userId: 14 training_loss:  3.7741433616514852\n",
            "userId: 15 training_loss:  1.8826757566706456\n",
            "userId: 16 training_loss:  3.1593562871055516\n",
            "userId: 17 training_loss:  2.0277094129692825\n",
            "userId: 18 training_loss:  3.453860270572253\n",
            "userId: 19 training_loss:  4.227423756919278\n",
            "userId: 20 training_loss:  4.696928542899938\n",
            "Evaluating model...\n",
            "computed_loss: 1.467435991929537\n",
            "Starting round 41\n",
            "userId: 0 training_loss:  4.886350993443346\n",
            "userId: 1 training_loss:  5.246262639678223\n",
            "userId: 2 training_loss:  3.255605323597115\n",
            "userId: 3 training_loss:  4.512521765428904\n",
            "userId: 4 training_loss:  3.3358168803301487\n",
            "userId: 5 training_loss:  0.9338716546566234\n",
            "userId: 6 training_loss:  1.5604950218194216\n",
            "userId: 7 training_loss:  4.559189418906143\n",
            "userId: 8 training_loss:  5.361482191703621\n",
            "userId: 9 training_loss:  3.7201382146955844\n",
            "userId: 10 training_loss:  1.237358095109576\n",
            "userId: 11 training_loss:  3.172824171884287\n",
            "userId: 12 training_loss:  4.583174861078211\n",
            "userId: 13 training_loss:  4.924343343542238\n",
            "userId: 14 training_loss:  3.196292629381116\n",
            "userId: 15 training_loss:  2.4324778148553703\n",
            "userId: 16 training_loss:  3.2360165622907124\n",
            "userId: 17 training_loss:  1.8901381994333977\n",
            "userId: 18 training_loss:  3.392723540778708\n",
            "userId: 19 training_loss:  4.213582624104029\n",
            "userId: 20 training_loss:  3.9503880901465656\n",
            "Evaluating model...\n",
            "computed_loss: 1.461657209672203\n",
            "Starting round 42\n",
            "userId: 0 training_loss:  5.485089991055164\n",
            "userId: 1 training_loss:  4.446541844519691\n",
            "userId: 2 training_loss:  2.8776699620841426\n",
            "userId: 3 training_loss:  4.105887125692648\n",
            "userId: 4 training_loss:  2.6761755639200713\n",
            "userId: 5 training_loss:  1.2017721931370697\n",
            "userId: 6 training_loss:  1.7423434991587894\n",
            "userId: 7 training_loss:  4.166556251608547\n",
            "userId: 8 training_loss:  5.5320914901679\n",
            "userId: 9 training_loss:  2.7586404448498114\n",
            "userId: 10 training_loss:  1.3161564491427478\n",
            "userId: 11 training_loss:  3.8578367310679305\n",
            "userId: 12 training_loss:  4.220472562689597\n",
            "userId: 13 training_loss:  4.807911864287327\n",
            "userId: 14 training_loss:  5.109127583019031\n",
            "userId: 15 training_loss:  2.2065161644462896\n",
            "userId: 16 training_loss:  2.8605243216231915\n",
            "userId: 17 training_loss:  2.1485244044250726\n",
            "userId: 18 training_loss:  3.3486473302806212\n",
            "userId: 19 training_loss:  4.308501982160666\n",
            "userId: 20 training_loss:  3.625636689715833\n",
            "Evaluating model...\n",
            "computed_loss: 1.624440451479603\n",
            "Starting round 43\n",
            "userId: 0 training_loss:  5.342140753510933\n",
            "userId: 1 training_loss:  4.725307670805709\n",
            "userId: 2 training_loss:  3.2984642513369797\n",
            "userId: 3 training_loss:  4.107368348512859\n",
            "userId: 4 training_loss:  2.974162096324467\n",
            "userId: 5 training_loss:  1.1317530568379008\n",
            "userId: 6 training_loss:  1.6915645094867358\n",
            "userId: 7 training_loss:  4.349185860691824\n",
            "userId: 8 training_loss:  5.697711002192337\n",
            "userId: 9 training_loss:  3.269588971850136\n",
            "userId: 10 training_loss:  1.3501433268065886\n",
            "userId: 11 training_loss:  4.032177167338109\n",
            "userId: 12 training_loss:  4.596776179483139\n",
            "userId: 13 training_loss:  4.555647614545161\n",
            "userId: 14 training_loss:  3.477469350381287\n",
            "userId: 15 training_loss:  2.0376577320151332\n",
            "userId: 16 training_loss:  2.9835234077181054\n",
            "userId: 17 training_loss:  2.1155843331785107\n",
            "userId: 18 training_loss:  2.5883919593627436\n",
            "userId: 19 training_loss:  4.842740384777365\n",
            "userId: 20 training_loss:  3.8412781804038554\n",
            "Evaluating model...\n",
            "computed_loss: 1.5293002970839895\n",
            "Starting round 44\n",
            "userId: 0 training_loss:  4.955170019627099\n",
            "userId: 1 training_loss:  4.690817905447733\n",
            "userId: 2 training_loss:  2.9383002522780197\n",
            "userId: 3 training_loss:  3.4597720610934575\n",
            "userId: 4 training_loss:  3.0064664711218234\n",
            "userId: 5 training_loss:  0.926007399052177\n",
            "userId: 6 training_loss:  1.7549475159044357\n",
            "userId: 7 training_loss:  4.29150009633721\n",
            "userId: 8 training_loss:  5.365391313047443\n",
            "userId: 9 training_loss:  2.9559621171498747\n",
            "userId: 10 training_loss:  1.2618075798383084\n",
            "userId: 11 training_loss:  3.000254363175572\n",
            "userId: 12 training_loss:  3.570154042140196\n",
            "userId: 13 training_loss:  4.231166980036607\n",
            "userId: 14 training_loss:  3.3360155748959466\n",
            "userId: 15 training_loss:  2.426636152873151\n",
            "userId: 16 training_loss:  3.29482816949048\n",
            "userId: 17 training_loss:  2.4092327292513978\n",
            "userId: 18 training_loss:  3.0294933014814163\n",
            "userId: 19 training_loss:  4.369759287686145\n",
            "userId: 20 training_loss:  3.741141093332254\n",
            "Evaluating model...\n",
            "computed_loss: 1.5241731966361485\n",
            "Starting round 45\n",
            "userId: 0 training_loss:  5.035009735716748\n",
            "userId: 1 training_loss:  4.865203290129154\n",
            "userId: 2 training_loss:  3.1000457658539355\n",
            "userId: 3 training_loss:  4.29544868462984\n",
            "userId: 4 training_loss:  3.193030316663124\n",
            "userId: 5 training_loss:  0.9099206875347597\n",
            "userId: 6 training_loss:  1.848269114940663\n",
            "userId: 7 training_loss:  3.9173491016280613\n",
            "userId: 8 training_loss:  5.337445534899068\n",
            "userId: 9 training_loss:  3.621550555224691\n",
            "userId: 10 training_loss:  1.323285544970282\n",
            "userId: 11 training_loss:  3.0861396050244743\n",
            "userId: 12 training_loss:  4.095299607310295\n",
            "userId: 13 training_loss:  4.45600595005589\n",
            "userId: 14 training_loss:  3.5431015334591622\n",
            "userId: 15 training_loss:  1.9646131382652012\n",
            "userId: 16 training_loss:  3.0928501249545652\n",
            "userId: 17 training_loss:  2.2330101997523633\n",
            "userId: 18 training_loss:  3.7508383764460502\n",
            "userId: 19 training_loss:  3.6775083198790286\n",
            "userId: 20 training_loss:  5.1930958368543205\n",
            "Evaluating model...\n",
            "computed_loss: 1.4574308696739269\n",
            "Starting round 46\n",
            "userId: 0 training_loss:  5.127513087625272\n",
            "userId: 1 training_loss:  4.407147490445334\n",
            "userId: 2 training_loss:  3.302667024165521\n",
            "userId: 3 training_loss:  3.6443124672002134\n",
            "userId: 4 training_loss:  3.5389064174321554\n",
            "userId: 5 training_loss:  1.248757544763319\n",
            "userId: 6 training_loss:  1.6187525114715235\n",
            "userId: 7 training_loss:  4.554439869890431\n",
            "userId: 8 training_loss:  5.726856072108172\n",
            "userId: 9 training_loss:  3.0218129914896954\n",
            "userId: 10 training_loss:  1.3076571438371503\n",
            "userId: 11 training_loss:  3.028070400821618\n",
            "userId: 12 training_loss:  3.5936320706809304\n",
            "userId: 13 training_loss:  3.9706668443765336\n",
            "userId: 14 training_loss:  3.3292817336333136\n",
            "userId: 15 training_loss:  2.0962597372105147\n",
            "userId: 16 training_loss:  2.6708981585603317\n",
            "userId: 17 training_loss:  1.838777792840908\n",
            "userId: 18 training_loss:  2.930983760463448\n",
            "userId: 19 training_loss:  3.598116102236704\n",
            "userId: 20 training_loss:  3.876407299473051\n",
            "Evaluating model...\n",
            "computed_loss: 1.4481149923103462\n",
            "Starting round 47\n",
            "userId: 0 training_loss:  5.086451463911614\n",
            "userId: 1 training_loss:  4.323874688437839\n",
            "userId: 2 training_loss:  3.6407692717736864\n",
            "userId: 3 training_loss:  4.064676384031497\n",
            "userId: 4 training_loss:  2.7732963876493275\n",
            "userId: 5 training_loss:  1.0477577590066802\n",
            "userId: 6 training_loss:  1.5860135947149494\n",
            "userId: 7 training_loss:  4.232149609108376\n",
            "userId: 8 training_loss:  6.4492242353910525\n",
            "userId: 9 training_loss:  3.109774371679311\n",
            "userId: 10 training_loss:  1.3216930721569464\n",
            "userId: 11 training_loss:  3.271442494278035\n",
            "userId: 12 training_loss:  4.558488303284963\n",
            "userId: 13 training_loss:  4.351594774076128\n",
            "userId: 14 training_loss:  2.835718201926791\n",
            "userId: 15 training_loss:  1.9374651479657232\n",
            "userId: 16 training_loss:  2.8785536963284555\n",
            "userId: 17 training_loss:  2.033224884951217\n",
            "userId: 18 training_loss:  3.1211080828918987\n",
            "userId: 19 training_loss:  3.7390299430368605\n",
            "userId: 20 training_loss:  4.042143081420493\n",
            "Evaluating model...\n",
            "computed_loss: 1.6316664755323618\n",
            "Starting round 48\n",
            "userId: 0 training_loss:  5.365761332799556\n",
            "userId: 1 training_loss:  4.450654570552504\n",
            "userId: 2 training_loss:  2.6858325680195394\n",
            "userId: 3 training_loss:  3.533857132561141\n",
            "userId: 4 training_loss:  2.8605206952080424\n",
            "userId: 5 training_loss:  1.0934419518353242\n",
            "userId: 6 training_loss:  1.6576470849920777\n",
            "userId: 7 training_loss:  4.617463425890035\n",
            "userId: 8 training_loss:  5.77145227031174\n",
            "userId: 9 training_loss:  3.007900080479023\n",
            "userId: 10 training_loss:  1.3752201915823394\n",
            "userId: 11 training_loss:  5.614323542048274\n",
            "userId: 12 training_loss:  3.909874562939352\n",
            "userId: 13 training_loss:  4.4163595033289695\n",
            "userId: 14 training_loss:  3.1340821673952877\n",
            "userId: 15 training_loss:  2.3963822460901962\n",
            "userId: 16 training_loss:  4.334371635022584\n",
            "userId: 17 training_loss:  1.979282263487671\n",
            "userId: 18 training_loss:  3.195752220127455\n",
            "userId: 19 training_loss:  4.026698677700545\n",
            "userId: 20 training_loss:  4.455914680452297\n",
            "Evaluating model...\n",
            "computed_loss: 1.426425986937145\n",
            "Starting round 49\n",
            "userId: 0 training_loss:  5.248448223866306\n",
            "userId: 1 training_loss:  4.419999229008524\n",
            "userId: 2 training_loss:  2.9927134427993907\n",
            "userId: 3 training_loss:  4.0114448909377645\n",
            "userId: 4 training_loss:  3.8480224184856824\n",
            "userId: 5 training_loss:  1.1797024091586747\n",
            "userId: 6 training_loss:  1.8394913450569643\n",
            "userId: 7 training_loss:  4.2370930156978925\n",
            "userId: 8 training_loss:  6.4217778067096845\n",
            "userId: 9 training_loss:  3.3147443790188973\n",
            "userId: 10 training_loss:  1.2557749533014013\n",
            "userId: 11 training_loss:  2.473498677730207\n",
            "userId: 12 training_loss:  4.059259893866146\n",
            "userId: 13 training_loss:  3.9630022305868216\n",
            "userId: 14 training_loss:  3.652410890559485\n",
            "userId: 15 training_loss:  2.0779768119259994\n",
            "userId: 16 training_loss:  3.1234361669102415\n",
            "userId: 17 training_loss:  2.118518924474501\n",
            "userId: 18 training_loss:  3.642539237211544\n",
            "userId: 19 training_loss:  3.503066544336724\n",
            "userId: 20 training_loss:  4.781621935707812\n",
            "Evaluating model...\n",
            "computed_loss: 1.4161225661051864\n",
            "Starting round 50\n",
            "userId: 0 training_loss:  5.064620295199039\n",
            "userId: 1 training_loss:  4.915711022974623\n",
            "userId: 2 training_loss:  3.468462844408657\n",
            "userId: 3 training_loss:  4.325759425214821\n",
            "userId: 4 training_loss:  3.5982903860726525\n",
            "userId: 5 training_loss:  1.0480912439531127\n",
            "userId: 6 training_loss:  1.7442819166019956\n",
            "userId: 7 training_loss:  4.59192413088004\n",
            "userId: 8 training_loss:  5.4587273164601\n",
            "userId: 9 training_loss:  3.419388483718766\n",
            "userId: 10 training_loss:  1.4620245291098621\n",
            "userId: 11 training_loss:  4.006737738344398\n",
            "userId: 12 training_loss:  3.5401934169303706\n",
            "userId: 13 training_loss:  3.8608898789746378\n",
            "userId: 14 training_loss:  3.4907000756443542\n",
            "userId: 15 training_loss:  2.2896742137477792\n",
            "userId: 16 training_loss:  2.8806308867625665\n",
            "userId: 17 training_loss:  2.42993502729869\n",
            "userId: 18 training_loss:  2.970288576396345\n",
            "userId: 19 training_loss:  3.595176440452623\n",
            "userId: 20 training_loss:  3.7635824433264076\n",
            "Evaluating model...\n",
            "computed_loss: 1.4033493398362826\n",
            "Starting round 51\n",
            "userId: 0 training_loss:  5.253212706515716\n",
            "userId: 1 training_loss:  4.295524291540444\n",
            "userId: 2 training_loss:  3.2766818134995725\n",
            "userId: 3 training_loss:  4.656891657580785\n",
            "userId: 4 training_loss:  3.269973268852408\n",
            "userId: 5 training_loss:  1.0544503665200762\n",
            "userId: 6 training_loss:  1.6743407684147822\n",
            "userId: 7 training_loss:  4.629017345891324\n",
            "userId: 8 training_loss:  5.394403359583824\n",
            "userId: 9 training_loss:  3.895203481665257\n",
            "userId: 10 training_loss:  1.3264613462640535\n",
            "userId: 11 training_loss:  3.452006537408786\n",
            "userId: 12 training_loss:  3.4157176240578906\n",
            "userId: 13 training_loss:  4.1004894212381195\n",
            "userId: 14 training_loss:  3.134091796367444\n",
            "userId: 15 training_loss:  2.2298798007230944\n",
            "userId: 16 training_loss:  2.565055201220564\n",
            "userId: 17 training_loss:  2.3299242575769386\n",
            "userId: 18 training_loss:  3.6309194669553913\n",
            "userId: 19 training_loss:  3.9984112287822384\n",
            "userId: 20 training_loss:  3.7350174383788355\n",
            "Evaluating model...\n",
            "computed_loss: 1.2798554293239968\n",
            "Starting round 52\n",
            "userId: 0 training_loss:  4.829421125613445\n",
            "userId: 1 training_loss:  4.612685245787935\n",
            "userId: 2 training_loss:  2.9404024442841767\n",
            "userId: 3 training_loss:  4.138603595098568\n",
            "userId: 4 training_loss:  3.5130646810499493\n",
            "userId: 5 training_loss:  0.8889706025392922\n",
            "userId: 6 training_loss:  1.5978071159302125\n",
            "userId: 7 training_loss:  3.8334709733540917\n",
            "userId: 8 training_loss:  6.422754939755164\n",
            "userId: 9 training_loss:  2.9115783685517647\n",
            "userId: 10 training_loss:  1.4094708351251846\n",
            "userId: 11 training_loss:  2.613434817910305\n",
            "userId: 12 training_loss:  4.171940722392757\n",
            "userId: 13 training_loss:  4.334635357121688\n",
            "userId: 14 training_loss:  3.5531772504355756\n",
            "userId: 15 training_loss:  2.192463834012375\n",
            "userId: 16 training_loss:  3.5875977450245573\n",
            "userId: 17 training_loss:  2.4551830496579887\n",
            "userId: 18 training_loss:  3.5422052725387103\n",
            "userId: 19 training_loss:  3.790336660602089\n",
            "userId: 20 training_loss:  3.5525905845210657\n",
            "Evaluating model...\n",
            "computed_loss: 1.543820340071101\n",
            "Starting round 53\n",
            "userId: 0 training_loss:  4.791939887702986\n",
            "userId: 1 training_loss:  4.4917752256043\n",
            "userId: 2 training_loss:  2.674268433769879\n",
            "userId: 3 training_loss:  4.198535148039683\n",
            "userId: 4 training_loss:  3.4054904173020475\n",
            "userId: 5 training_loss:  1.0002704547365493\n",
            "userId: 6 training_loss:  1.6502217054301695\n",
            "userId: 7 training_loss:  4.117337411506236\n",
            "userId: 8 training_loss:  5.90743963336587\n",
            "userId: 9 training_loss:  2.990154331587687\n",
            "userId: 10 training_loss:  1.3990204115939322\n",
            "userId: 11 training_loss:  2.6989288599589876\n",
            "userId: 12 training_loss:  3.4675748986458204\n",
            "userId: 13 training_loss:  4.166254045129917\n",
            "userId: 14 training_loss:  2.79884654742145\n",
            "userId: 15 training_loss:  2.2015331906523485\n",
            "userId: 16 training_loss:  2.5005858184418885\n",
            "userId: 17 training_loss:  2.2055758668205043\n",
            "userId: 18 training_loss:  3.1867647499987677\n",
            "userId: 19 training_loss:  3.789436163327417\n",
            "userId: 20 training_loss:  3.8004221042282764\n",
            "Evaluating model...\n",
            "computed_loss: 1.4747950186605092\n",
            "Starting round 54\n",
            "userId: 0 training_loss:  4.455276018369234\n",
            "userId: 1 training_loss:  4.1034591509084235\n",
            "userId: 2 training_loss:  3.292919836140521\n",
            "userId: 3 training_loss:  3.778597146971729\n",
            "userId: 4 training_loss:  3.4021122045477816\n",
            "userId: 5 training_loss:  1.0766173589725951\n",
            "userId: 6 training_loss:  1.8964035399469896\n",
            "userId: 7 training_loss:  3.7221824810683244\n",
            "userId: 8 training_loss:  6.137976167947024\n",
            "userId: 9 training_loss:  2.8388471838013016\n",
            "userId: 10 training_loss:  1.3130402917324606\n",
            "userId: 11 training_loss:  3.191042431539188\n",
            "userId: 12 training_loss:  3.1086325826315777\n",
            "userId: 13 training_loss:  4.251043610595314\n",
            "userId: 14 training_loss:  3.152026290557573\n",
            "userId: 15 training_loss:  2.3185521314019097\n",
            "userId: 16 training_loss:  2.538044515917231\n",
            "userId: 17 training_loss:  2.101742138785746\n",
            "userId: 18 training_loss:  3.0726721838231215\n",
            "userId: 19 training_loss:  3.712572156167417\n",
            "userId: 20 training_loss:  3.892506727379203\n",
            "Evaluating model...\n",
            "computed_loss: 1.3239380760598647\n",
            "Starting round 55\n",
            "userId: 0 training_loss:  4.807015989872427\n",
            "userId: 1 training_loss:  4.664661444146228\n",
            "userId: 2 training_loss:  2.715540578030917\n",
            "userId: 3 training_loss:  4.019731209881776\n",
            "userId: 4 training_loss:  3.619841532611691\n",
            "userId: 5 training_loss:  0.9157353200123136\n",
            "userId: 6 training_loss:  1.9912612037034567\n",
            "userId: 7 training_loss:  4.174123988480546\n",
            "userId: 8 training_loss:  5.478355395820157\n",
            "userId: 9 training_loss:  3.9162701914568174\n",
            "userId: 10 training_loss:  1.2869877568622248\n",
            "userId: 11 training_loss:  2.6153687003791264\n",
            "userId: 12 training_loss:  3.9008866968338536\n",
            "userId: 13 training_loss:  5.423410289101991\n",
            "userId: 14 training_loss:  2.7297576110554336\n",
            "userId: 15 training_loss:  2.434631600017421\n",
            "userId: 16 training_loss:  3.480028109796146\n",
            "userId: 17 training_loss:  2.1115009597818504\n",
            "userId: 18 training_loss:  2.891175216703322\n",
            "userId: 19 training_loss:  3.685574644378692\n",
            "userId: 20 training_loss:  4.38175047395597\n",
            "Evaluating model...\n",
            "computed_loss: 1.4330651901562956\n",
            "Starting round 56\n",
            "userId: 0 training_loss:  4.741329217395444\n",
            "userId: 1 training_loss:  5.070631878146921\n",
            "userId: 2 training_loss:  3.136915773138477\n",
            "userId: 3 training_loss:  3.7045983219536742\n",
            "userId: 4 training_loss:  2.7036139628922653\n",
            "userId: 5 training_loss:  0.8977760965223396\n",
            "userId: 6 training_loss:  1.7545135442318138\n",
            "userId: 7 training_loss:  3.7273755703343143\n",
            "userId: 8 training_loss:  4.877313896246099\n",
            "userId: 9 training_loss:  2.924279265848692\n",
            "userId: 10 training_loss:  1.4348638909759086\n",
            "userId: 11 training_loss:  4.0475992595866455\n",
            "userId: 12 training_loss:  3.9694631959043107\n",
            "userId: 13 training_loss:  4.421495513830898\n",
            "userId: 14 training_loss:  3.031649338218819\n",
            "userId: 15 training_loss:  2.593686722540002\n",
            "userId: 16 training_loss:  3.166093373069007\n",
            "userId: 17 training_loss:  2.3794865380836567\n",
            "userId: 18 training_loss:  3.2733822984001923\n",
            "userId: 19 training_loss:  3.3005367340924368\n",
            "userId: 20 training_loss:  3.556393285614895\n",
            "Evaluating model...\n",
            "computed_loss: 1.5379805092330592\n",
            "Starting round 57\n",
            "userId: 0 training_loss:  4.802475388452257\n",
            "userId: 1 training_loss:  4.454520984105542\n",
            "userId: 2 training_loss:  2.980365310227414\n",
            "userId: 3 training_loss:  4.15858939284595\n",
            "userId: 4 training_loss:  3.288697891265083\n",
            "userId: 5 training_loss:  1.1594247876075794\n",
            "userId: 6 training_loss:  1.787023499679306\n",
            "userId: 7 training_loss:  4.164987353486842\n",
            "userId: 8 training_loss:  5.845349812457054\n",
            "userId: 9 training_loss:  3.212078448047773\n",
            "userId: 10 training_loss:  1.171756035231727\n",
            "userId: 11 training_loss:  3.714507763591796\n",
            "userId: 12 training_loss:  4.202085824809425\n",
            "userId: 13 training_loss:  4.99955537640823\n",
            "userId: 14 training_loss:  3.018708657164868\n",
            "userId: 15 training_loss:  2.1557522732563372\n",
            "userId: 16 training_loss:  3.4748563198251565\n",
            "userId: 17 training_loss:  2.075687123210429\n",
            "userId: 18 training_loss:  3.9889442271503244\n",
            "userId: 19 training_loss:  3.8801155427893326\n",
            "userId: 20 training_loss:  4.455400772473147\n",
            "Evaluating model...\n",
            "computed_loss: 1.3930329340977852\n",
            "Starting round 58\n",
            "userId: 0 training_loss:  4.704133143523788\n",
            "userId: 1 training_loss:  4.710679838513829\n",
            "userId: 2 training_loss:  3.3676218114295637\n",
            "userId: 3 training_loss:  4.09991403474417\n",
            "userId: 4 training_loss:  3.368451812609249\n",
            "userId: 5 training_loss:  1.0190242360193695\n",
            "userId: 6 training_loss:  1.768028949222733\n",
            "userId: 7 training_loss:  4.41324811238916\n",
            "userId: 8 training_loss:  5.741149851892424\n",
            "userId: 9 training_loss:  2.680185620135875\n",
            "userId: 10 training_loss:  1.1798164756226857\n",
            "userId: 11 training_loss:  3.276338911023339\n",
            "userId: 12 training_loss:  4.170683193767235\n",
            "userId: 13 training_loss:  4.2071060037201775\n",
            "userId: 14 training_loss:  3.4696063712626612\n",
            "userId: 15 training_loss:  2.237215079448327\n",
            "userId: 16 training_loss:  3.0751101192785173\n",
            "userId: 17 training_loss:  2.2255525825962708\n",
            "userId: 18 training_loss:  3.1073899231883706\n",
            "userId: 19 training_loss:  3.9360633069266457\n",
            "userId: 20 training_loss:  4.357741712354407\n",
            "Evaluating model...\n",
            "computed_loss: 1.6880324485861882\n",
            "Starting round 59\n",
            "userId: 0 training_loss:  4.851472779359549\n",
            "userId: 1 training_loss:  4.370056181615117\n",
            "userId: 2 training_loss:  3.282108154446557\n",
            "userId: 3 training_loss:  3.667871812252261\n",
            "userId: 4 training_loss:  3.150121998706333\n",
            "userId: 5 training_loss:  1.0500678913483017\n",
            "userId: 6 training_loss:  1.7615565925393413\n",
            "userId: 7 training_loss:  4.074038227791045\n",
            "userId: 8 training_loss:  6.31733361112963\n",
            "userId: 9 training_loss:  2.6503596529627145\n",
            "userId: 10 training_loss:  1.3996869903400846\n",
            "userId: 11 training_loss:  3.077278865884998\n",
            "userId: 12 training_loss:  3.351969159195889\n",
            "userId: 13 training_loss:  4.635772559354035\n",
            "userId: 14 training_loss:  3.4394456300929734\n",
            "userId: 15 training_loss:  2.332229523677051\n",
            "userId: 16 training_loss:  2.8543157181111556\n",
            "userId: 17 training_loss:  2.0073199749286257\n",
            "userId: 18 training_loss:  3.5542998032938193\n",
            "userId: 19 training_loss:  3.3652821728015327\n",
            "userId: 20 training_loss:  3.6850899330536158\n",
            "Evaluating model...\n",
            "computed_loss: 1.4404556818956065\n",
            "Starting round 60\n",
            "userId: 0 training_loss:  4.896242190329377\n",
            "userId: 1 training_loss:  4.757817007623987\n",
            "userId: 2 training_loss:  3.1801206494081775\n",
            "userId: 3 training_loss:  3.9015338013636125\n",
            "userId: 4 training_loss:  2.917315409304554\n",
            "userId: 5 training_loss:  1.0058146784846256\n",
            "userId: 6 training_loss:  1.5397126265075343\n",
            "userId: 7 training_loss:  3.956144056604198\n",
            "userId: 8 training_loss:  4.859353355693921\n",
            "userId: 9 training_loss:  2.605089698480496\n",
            "userId: 10 training_loss:  1.3258432948487422\n",
            "userId: 11 training_loss:  2.4188803097997607\n",
            "userId: 12 training_loss:  3.4330112044927334\n",
            "userId: 13 training_loss:  4.213530559454847\n",
            "userId: 14 training_loss:  3.168920639776122\n",
            "userId: 15 training_loss:  2.133678322607206\n",
            "userId: 16 training_loss:  2.8504727920940502\n",
            "userId: 17 training_loss:  1.8110311147161924\n",
            "userId: 18 training_loss:  3.0167658585300865\n",
            "userId: 19 training_loss:  3.434693051903948\n",
            "userId: 20 training_loss:  4.076886635352\n",
            "Evaluating model...\n",
            "computed_loss: 1.5292311764899877\n",
            "Starting round 61\n",
            "userId: 0 training_loss:  4.986241648734266\n",
            "userId: 1 training_loss:  4.397931701230699\n",
            "userId: 2 training_loss:  3.2353751773689607\n",
            "userId: 3 training_loss:  4.452034819982653\n",
            "userId: 4 training_loss:  2.970493932399785\n",
            "userId: 5 training_loss:  1.1024976345958888\n",
            "userId: 6 training_loss:  1.8570554456107868\n",
            "userId: 7 training_loss:  3.729881283787294\n",
            "userId: 8 training_loss:  5.442894608073938\n",
            "userId: 9 training_loss:  3.180104178942544\n",
            "userId: 10 training_loss:  1.3386505895114267\n",
            "userId: 11 training_loss:  2.785037162424794\n",
            "userId: 12 training_loss:  3.4440544495605416\n",
            "userId: 13 training_loss:  4.690331254363699\n",
            "userId: 14 training_loss:  3.12380414184066\n",
            "userId: 15 training_loss:  1.8470076743595747\n",
            "userId: 16 training_loss:  3.185111286646715\n",
            "userId: 17 training_loss:  2.126140547575004\n",
            "userId: 18 training_loss:  4.021132331793906\n",
            "userId: 19 training_loss:  3.9815518886919223\n",
            "userId: 20 training_loss:  4.136672221988054\n",
            "Evaluating model...\n",
            "computed_loss: 1.4781862157306633\n",
            "Starting round 62\n",
            "userId: 0 training_loss:  5.424211487561622\n",
            "userId: 1 training_loss:  5.083890208281633\n",
            "userId: 2 training_loss:  2.7692560868442913\n",
            "userId: 3 training_loss:  4.052355191115797\n",
            "userId: 4 training_loss:  3.2401717385416626\n",
            "userId: 5 training_loss:  0.9007111943766931\n",
            "userId: 6 training_loss:  1.5807899336843656\n",
            "userId: 7 training_loss:  3.649184377640586\n",
            "userId: 8 training_loss:  5.622180725515341\n",
            "userId: 9 training_loss:  3.017954768045901\n",
            "userId: 10 training_loss:  1.2100648104085745\n",
            "userId: 11 training_loss:  2.8294207042013366\n",
            "userId: 12 training_loss:  3.927308603964769\n",
            "userId: 13 training_loss:  4.8179941741808054\n",
            "userId: 14 training_loss:  2.8531733281592375\n",
            "userId: 15 training_loss:  2.060235798769495\n",
            "userId: 16 training_loss:  2.98541966450614\n",
            "userId: 17 training_loss:  2.415290016662886\n",
            "userId: 18 training_loss:  3.511556651970551\n",
            "userId: 19 training_loss:  4.296391887575316\n",
            "userId: 20 training_loss:  3.705025672928511\n",
            "Evaluating model...\n",
            "computed_loss: 1.550417355994356\n",
            "Starting round 63\n",
            "userId: 0 training_loss:  5.166005281092065\n",
            "userId: 1 training_loss:  4.610891425493492\n",
            "userId: 2 training_loss:  3.3537427839509406\n",
            "userId: 3 training_loss:  3.610692769712506\n",
            "userId: 4 training_loss:  3.4832481319850084\n",
            "userId: 5 training_loss:  1.1022767848208288\n",
            "userId: 6 training_loss:  1.6689245833649977\n",
            "userId: 7 training_loss:  4.200820616431424\n",
            "userId: 8 training_loss:  5.326581292507303\n",
            "userId: 9 training_loss:  2.5617790393245063\n",
            "userId: 10 training_loss:  1.3288110303607983\n",
            "userId: 11 training_loss:  2.882238866146367\n",
            "userId: 12 training_loss:  4.327846293174137\n",
            "userId: 13 training_loss:  4.2013378520826645\n",
            "userId: 14 training_loss:  2.8444746104803165\n",
            "userId: 15 training_loss:  2.4140650061838596\n",
            "userId: 16 training_loss:  3.4038484542033194\n",
            "userId: 17 training_loss:  2.1147406554541286\n",
            "userId: 18 training_loss:  3.347837792829582\n",
            "userId: 19 training_loss:  3.584922288145129\n",
            "userId: 20 training_loss:  4.43144951078449\n",
            "Evaluating model...\n",
            "computed_loss: 1.3679708239544208\n",
            "Starting round 64\n",
            "userId: 0 training_loss:  5.460173038481129\n",
            "userId: 1 training_loss:  4.631082210814351\n",
            "userId: 2 training_loss:  3.875285559127208\n",
            "userId: 3 training_loss:  3.7583617345050833\n",
            "userId: 4 training_loss:  3.6101286873802985\n",
            "userId: 5 training_loss:  1.1239108059981338\n",
            "userId: 6 training_loss:  1.8389007169462324\n",
            "userId: 7 training_loss:  3.7445088759129064\n",
            "userId: 8 training_loss:  5.188739257370443\n",
            "userId: 9 training_loss:  4.003363809259288\n",
            "userId: 10 training_loss:  1.3833792658660158\n",
            "userId: 11 training_loss:  3.1268456723720135\n",
            "userId: 12 training_loss:  3.792659491588764\n",
            "userId: 13 training_loss:  4.951545390064086\n",
            "userId: 14 training_loss:  3.8530905702756284\n",
            "userId: 15 training_loss:  2.0805426486520213\n",
            "userId: 16 training_loss:  2.8277426089667115\n",
            "userId: 17 training_loss:  2.3976873983410707\n",
            "userId: 18 training_loss:  3.094503358795218\n",
            "userId: 19 training_loss:  3.230303763194569\n",
            "userId: 20 training_loss:  3.4922748652224023\n",
            "Evaluating model...\n",
            "computed_loss: 1.6729314416143886\n",
            "Starting round 65\n",
            "userId: 0 training_loss:  4.377535423627282\n",
            "userId: 1 training_loss:  4.590363779138391\n",
            "userId: 2 training_loss:  3.613973120349338\n",
            "userId: 3 training_loss:  3.8726544034213335\n",
            "userId: 4 training_loss:  3.7108886255200986\n",
            "userId: 5 training_loss:  1.082678775092933\n",
            "userId: 6 training_loss:  1.7489674243775635\n",
            "userId: 7 training_loss:  3.924700434826229\n",
            "userId: 8 training_loss:  4.970778533776313\n",
            "userId: 9 training_loss:  3.3600595646431315\n",
            "userId: 10 training_loss:  1.4716236197934818\n",
            "userId: 11 training_loss:  3.0659108731653855\n",
            "userId: 12 training_loss:  3.960778513681882\n",
            "userId: 13 training_loss:  4.412046781110796\n",
            "userId: 14 training_loss:  3.274821495866795\n",
            "userId: 15 training_loss:  2.3627408753197203\n",
            "userId: 16 training_loss:  3.261206839790512\n",
            "userId: 17 training_loss:  2.6529199699867205\n",
            "userId: 18 training_loss:  3.4685462238304217\n",
            "userId: 19 training_loss:  3.752246102686282\n",
            "userId: 20 training_loss:  3.7855044109883176\n",
            "Evaluating model...\n",
            "computed_loss: 1.4086004373199155\n",
            "Starting round 66\n",
            "userId: 0 training_loss:  4.549607921209284\n",
            "userId: 1 training_loss:  5.184642307059791\n",
            "userId: 2 training_loss:  2.747462108532519\n",
            "userId: 3 training_loss:  4.256656871797474\n",
            "userId: 4 training_loss:  3.49772667873738\n",
            "userId: 5 training_loss:  1.215501954665552\n",
            "userId: 6 training_loss:  1.7001970441244978\n",
            "userId: 7 training_loss:  4.469191251031019\n",
            "userId: 8 training_loss:  6.456629167879285\n",
            "userId: 9 training_loss:  2.8709958910991777\n",
            "userId: 10 training_loss:  1.3794400670375966\n",
            "userId: 11 training_loss:  3.9254296789479945\n",
            "userId: 12 training_loss:  3.515151073219402\n",
            "userId: 13 training_loss:  4.764944155263851\n",
            "userId: 14 training_loss:  2.9704762585851703\n",
            "userId: 15 training_loss:  1.9799649985604677\n",
            "userId: 16 training_loss:  3.030020484101944\n",
            "userId: 17 training_loss:  2.178044234872398\n",
            "userId: 18 training_loss:  3.2836192653056577\n",
            "userId: 19 training_loss:  4.687125743713138\n",
            "userId: 20 training_loss:  4.67322089726043\n",
            "Evaluating model...\n",
            "computed_loss: 1.3190379555652751\n",
            "Starting round 67\n",
            "userId: 0 training_loss:  4.566537716407633\n",
            "userId: 1 training_loss:  4.817260639752442\n",
            "userId: 2 training_loss:  2.8801739503528307\n",
            "userId: 3 training_loss:  3.6509451445966734\n",
            "userId: 4 training_loss:  2.9344022527132614\n",
            "userId: 5 training_loss:  1.033041488039554\n",
            "userId: 6 training_loss:  1.5717852082975916\n",
            "userId: 7 training_loss:  4.087909094263443\n",
            "userId: 8 training_loss:  5.3001998865375075\n",
            "userId: 9 training_loss:  3.088216502380175\n",
            "userId: 10 training_loss:  1.306875753291163\n",
            "userId: 11 training_loss:  2.5606334307287044\n",
            "userId: 12 training_loss:  4.172588556152891\n",
            "userId: 13 training_loss:  4.511324646146839\n",
            "userId: 14 training_loss:  3.803089473679787\n",
            "userId: 15 training_loss:  2.447932852133351\n",
            "userId: 16 training_loss:  2.7089031879442302\n",
            "userId: 17 training_loss:  2.104769949200693\n",
            "userId: 18 training_loss:  3.665727288250306\n",
            "userId: 19 training_loss:  3.563382755226164\n",
            "userId: 20 training_loss:  4.086429065968317\n",
            "Evaluating model...\n",
            "computed_loss: 1.355275378766897\n",
            "Starting round 68\n",
            "userId: 0 training_loss:  5.27556683214981\n",
            "userId: 1 training_loss:  4.833614350612409\n",
            "userId: 2 training_loss:  3.087070813860079\n",
            "userId: 3 training_loss:  3.72830617387019\n",
            "userId: 4 training_loss:  3.174496223486744\n",
            "userId: 5 training_loss:  0.9765150268803862\n",
            "userId: 6 training_loss:  1.5823459611553807\n",
            "userId: 7 training_loss:  3.861558380039402\n",
            "userId: 8 training_loss:  5.746253457953176\n",
            "userId: 9 training_loss:  3.164961272578522\n",
            "userId: 10 training_loss:  1.3861029374157212\n",
            "userId: 11 training_loss:  3.0138388129628852\n",
            "userId: 12 training_loss:  3.7016524223134666\n",
            "userId: 13 training_loss:  4.237401696245439\n",
            "userId: 14 training_loss:  3.7189127926531107\n",
            "userId: 15 training_loss:  2.2811316758234392\n",
            "userId: 16 training_loss:  2.820578999330022\n",
            "userId: 17 training_loss:  2.2207350777149513\n",
            "userId: 18 training_loss:  3.5115442089792817\n",
            "userId: 19 training_loss:  4.2680752553905394\n",
            "userId: 20 training_loss:  3.9049946823709263\n",
            "Evaluating model...\n",
            "computed_loss: 1.5063392240728801\n",
            "Starting round 69\n",
            "userId: 0 training_loss:  5.269149384520561\n",
            "userId: 1 training_loss:  4.22953680059095\n",
            "userId: 2 training_loss:  2.7699367080386854\n",
            "userId: 3 training_loss:  4.1672445418336945\n",
            "userId: 4 training_loss:  2.7722627034537317\n",
            "userId: 5 training_loss:  1.0721919478197253\n",
            "userId: 6 training_loss:  1.6619774976248916\n",
            "userId: 7 training_loss:  4.155034068140341\n",
            "userId: 8 training_loss:  5.700890153784501\n",
            "userId: 9 training_loss:  3.7740881734244467\n",
            "userId: 10 training_loss:  1.3760566275578996\n",
            "userId: 11 training_loss:  2.6650658962712734\n",
            "userId: 12 training_loss:  3.6809757304008444\n",
            "userId: 13 training_loss:  4.348092398362093\n",
            "userId: 14 training_loss:  3.0458641932966044\n",
            "userId: 15 training_loss:  2.6560085610535555\n",
            "userId: 16 training_loss:  3.100439402214129\n",
            "userId: 17 training_loss:  2.2803355780393835\n",
            "userId: 18 training_loss:  3.1316823178982838\n",
            "userId: 19 training_loss:  3.1787122344006575\n",
            "userId: 20 training_loss:  3.998429205006225\n",
            "Evaluating model...\n",
            "computed_loss: 1.4178400494553154\n",
            "Starting round 70\n",
            "userId: 0 training_loss:  4.838286699380386\n",
            "userId: 1 training_loss:  4.689445279657271\n",
            "userId: 2 training_loss:  2.9680907341460143\n",
            "userId: 3 training_loss:  3.7373836684303754\n",
            "userId: 4 training_loss:  3.4660273179480976\n",
            "userId: 5 training_loss:  1.12149765656223\n",
            "userId: 6 training_loss:  1.517074324979066\n",
            "userId: 7 training_loss:  3.9384574113608144\n",
            "userId: 8 training_loss:  5.2583253006775434\n",
            "userId: 9 training_loss:  2.8430869448809677\n",
            "userId: 10 training_loss:  1.3356348638261741\n",
            "userId: 11 training_loss:  3.1402084153131753\n",
            "userId: 12 training_loss:  3.356815864685089\n",
            "userId: 13 training_loss:  4.78328047885646\n",
            "userId: 14 training_loss:  3.1088780197865304\n",
            "userId: 15 training_loss:  1.983547074240113\n",
            "userId: 16 training_loss:  3.946868918763647\n",
            "userId: 17 training_loss:  2.2067184213352045\n",
            "userId: 18 training_loss:  2.997783212048178\n",
            "userId: 19 training_loss:  3.941889735601234\n",
            "userId: 20 training_loss:  4.182884110190686\n",
            "Evaluating model...\n",
            "computed_loss: 1.493444065031423\n",
            "Starting round 71\n",
            "userId: 0 training_loss:  5.689165732803068\n",
            "userId: 1 training_loss:  5.3089113776171\n",
            "userId: 2 training_loss:  3.5257348627029246\n",
            "userId: 3 training_loss:  4.325324899185583\n",
            "userId: 4 training_loss:  2.864599197965596\n",
            "userId: 5 training_loss:  1.1694761123315047\n",
            "userId: 6 training_loss:  1.769153779951394\n",
            "userId: 7 training_loss:  3.8721920932238603\n",
            "userId: 8 training_loss:  5.667264745247743\n",
            "userId: 9 training_loss:  3.4876327367941387\n",
            "userId: 10 training_loss:  1.393084960454942\n",
            "userId: 11 training_loss:  2.6715891950813204\n",
            "userId: 12 training_loss:  3.787629624320509\n",
            "userId: 13 training_loss:  4.40173620438608\n",
            "userId: 14 training_loss:  2.9750100437371962\n",
            "userId: 15 training_loss:  2.2624512578008504\n",
            "userId: 16 training_loss:  3.1799462472825306\n",
            "userId: 17 training_loss:  1.938298314092998\n",
            "userId: 18 training_loss:  2.98453908650241\n",
            "userId: 19 training_loss:  3.845469490466699\n",
            "userId: 20 training_loss:  3.202119017382276\n",
            "Evaluating model...\n",
            "computed_loss: 1.4937766195288704\n",
            "Starting round 72\n",
            "userId: 0 training_loss:  5.023007178302083\n",
            "userId: 1 training_loss:  3.8272325647891874\n",
            "userId: 2 training_loss:  3.564265430980762\n",
            "userId: 3 training_loss:  3.688606515981847\n",
            "userId: 4 training_loss:  2.9985256323821483\n",
            "userId: 5 training_loss:  1.1248289224870942\n",
            "userId: 6 training_loss:  1.720071427052948\n",
            "userId: 7 training_loss:  4.184827567633723\n",
            "userId: 8 training_loss:  5.848685249299004\n",
            "userId: 9 training_loss:  3.3925483913938193\n",
            "userId: 10 training_loss:  1.447393280625849\n",
            "userId: 11 training_loss:  2.9415003421673083\n",
            "userId: 12 training_loss:  3.629084416079338\n",
            "userId: 13 training_loss:  4.469068912680571\n",
            "userId: 14 training_loss:  3.6330412591964554\n",
            "userId: 15 training_loss:  2.1475916824344377\n",
            "userId: 16 training_loss:  3.1997446999499077\n",
            "userId: 17 training_loss:  2.2315160542641053\n",
            "userId: 18 training_loss:  3.151839924320485\n",
            "userId: 19 training_loss:  4.320134457157218\n",
            "userId: 20 training_loss:  3.761203694900008\n",
            "Evaluating model...\n",
            "computed_loss: 1.4135392762702044\n",
            "Starting round 73\n",
            "userId: 0 training_loss:  4.751872810601893\n",
            "userId: 1 training_loss:  5.258869796501644\n",
            "userId: 2 training_loss:  2.849459774402168\n",
            "userId: 3 training_loss:  3.5735754357535625\n",
            "userId: 4 training_loss:  3.8312658803704935\n",
            "userId: 5 training_loss:  0.9790579826097924\n",
            "userId: 6 training_loss:  1.8518298486276952\n",
            "userId: 7 training_loss:  3.9272009062137365\n",
            "userId: 8 training_loss:  4.894529049970821\n",
            "userId: 9 training_loss:  2.6204271301660933\n",
            "userId: 10 training_loss:  1.4584870146398698\n",
            "userId: 11 training_loss:  2.981335712657164\n",
            "userId: 12 training_loss:  3.8779029154066613\n",
            "userId: 13 training_loss:  4.167562952740619\n",
            "userId: 14 training_loss:  3.4995634963493756\n",
            "userId: 15 training_loss:  2.1240482421440294\n",
            "userId: 16 training_loss:  2.6957095054652798\n",
            "userId: 17 training_loss:  1.9743260397961588\n",
            "userId: 18 training_loss:  3.205163786531828\n",
            "userId: 19 training_loss:  3.4657278669934746\n",
            "userId: 20 training_loss:  4.417042575870026\n",
            "Evaluating model...\n",
            "computed_loss: 1.2852320744718166\n",
            "Starting round 74\n",
            "userId: 0 training_loss:  5.2966957732763476\n",
            "userId: 1 training_loss:  4.000685699811323\n",
            "userId: 2 training_loss:  3.0547928784725835\n",
            "userId: 3 training_loss:  3.922504384705083\n",
            "userId: 4 training_loss:  3.032523716986186\n",
            "userId: 5 training_loss:  1.0778912190458265\n",
            "userId: 6 training_loss:  1.5390688727257795\n",
            "userId: 7 training_loss:  4.029338238453908\n",
            "userId: 8 training_loss:  5.318969682883623\n",
            "userId: 9 training_loss:  3.098078034142388\n",
            "userId: 10 training_loss:  1.2127441096470755\n",
            "userId: 11 training_loss:  4.89937041670762\n",
            "userId: 12 training_loss:  3.1258294475867876\n",
            "userId: 13 training_loss:  3.883384439987482\n",
            "userId: 14 training_loss:  3.999491821829735\n",
            "userId: 15 training_loss:  2.1276884916994594\n",
            "userId: 16 training_loss:  2.503089180460084\n",
            "userId: 17 training_loss:  2.056362247187771\n",
            "userId: 18 training_loss:  3.4210979043496885\n",
            "userId: 19 training_loss:  3.7739392360573176\n",
            "userId: 20 training_loss:  3.8246677552423947\n",
            "Evaluating model...\n",
            "computed_loss: 1.386294065275782\n",
            "Starting round 75\n",
            "userId: 0 training_loss:  4.8309929110950165\n",
            "userId: 1 training_loss:  5.781160056812692\n",
            "userId: 2 training_loss:  3.1692420586171965\n",
            "userId: 3 training_loss:  4.105195163326623\n",
            "userId: 4 training_loss:  3.413450387462371\n",
            "userId: 5 training_loss:  1.149735534640684\n",
            "userId: 6 training_loss:  1.9592255749617433\n",
            "userId: 7 training_loss:  3.899761952083916\n",
            "userId: 8 training_loss:  5.776967355501663\n",
            "userId: 9 training_loss:  3.1365883539532424\n",
            "userId: 10 training_loss:  1.319342725801259\n",
            "userId: 11 training_loss:  3.1027181437366926\n",
            "userId: 12 training_loss:  3.698511143229058\n",
            "userId: 13 training_loss:  4.3717654524432294\n",
            "userId: 14 training_loss:  3.3274176384434577\n",
            "userId: 15 training_loss:  2.218847491154157\n",
            "userId: 16 training_loss:  3.086610576512535\n",
            "userId: 17 training_loss:  2.5215743897035567\n",
            "userId: 18 training_loss:  3.5904250817247685\n",
            "userId: 19 training_loss:  3.911548042764385\n",
            "userId: 20 training_loss:  3.2907275725044665\n",
            "Evaluating model...\n",
            "computed_loss: 1.402767855538068\n",
            "Starting round 76\n",
            "userId: 0 training_loss:  5.00849621305514\n",
            "userId: 1 training_loss:  4.051981887205797\n",
            "userId: 2 training_loss:  2.987970496047418\n",
            "userId: 3 training_loss:  3.31208354006226\n",
            "userId: 4 training_loss:  3.5342093609290544\n",
            "userId: 5 training_loss:  1.1268002098174374\n",
            "userId: 6 training_loss:  1.995372573930456\n",
            "userId: 7 training_loss:  4.288755535529446\n",
            "userId: 8 training_loss:  5.550302701998392\n",
            "userId: 9 training_loss:  2.8716606277282137\n",
            "userId: 10 training_loss:  1.2565135863248127\n",
            "userId: 11 training_loss:  3.1284307843211208\n",
            "userId: 12 training_loss:  3.3093833907215213\n",
            "userId: 13 training_loss:  4.210438801322033\n",
            "userId: 14 training_loss:  3.693419773555432\n",
            "userId: 15 training_loss:  2.1252818515309357\n",
            "userId: 16 training_loss:  2.543411948939207\n",
            "userId: 17 training_loss:  1.9034948648571046\n",
            "userId: 18 training_loss:  3.1851508883193014\n",
            "userId: 19 training_loss:  3.6154323844431473\n",
            "userId: 20 training_loss:  3.2574891205741885\n",
            "Evaluating model...\n",
            "computed_loss: 1.2841427835895818\n",
            "Starting round 77\n",
            "userId: 0 training_loss:  5.137928302752706\n",
            "userId: 1 training_loss:  4.0954509123551315\n",
            "userId: 2 training_loss:  2.8369587316729556\n",
            "userId: 3 training_loss:  4.351347991562359\n",
            "userId: 4 training_loss:  3.118486485005884\n",
            "userId: 5 training_loss:  1.1184702807029392\n",
            "userId: 6 training_loss:  1.7717073843665987\n",
            "userId: 7 training_loss:  3.6278593193045383\n",
            "userId: 8 training_loss:  5.7041838765155415\n",
            "userId: 9 training_loss:  3.3583476573062496\n",
            "userId: 10 training_loss:  1.3169395966453936\n",
            "userId: 11 training_loss:  2.6585312114716118\n",
            "userId: 12 training_loss:  3.9868334675781734\n",
            "userId: 13 training_loss:  4.86909062679142\n",
            "userId: 14 training_loss:  3.2240459642287\n",
            "userId: 15 training_loss:  2.2749340111253007\n",
            "userId: 16 training_loss:  2.894106736584029\n",
            "userId: 17 training_loss:  2.0918699142359585\n",
            "userId: 18 training_loss:  3.5902438796207425\n",
            "userId: 19 training_loss:  4.16877624568435\n",
            "userId: 20 training_loss:  4.580145552531451\n",
            "Evaluating model...\n",
            "computed_loss: 1.340384024113022\n",
            "Starting round 78\n",
            "userId: 0 training_loss:  4.913988267483024\n",
            "userId: 1 training_loss:  4.54743691874335\n",
            "userId: 2 training_loss:  3.190059024253022\n",
            "userId: 3 training_loss:  3.325260706609579\n",
            "userId: 4 training_loss:  3.2043835617300482\n",
            "userId: 5 training_loss:  0.9065388011280966\n",
            "userId: 6 training_loss:  1.6505445471372902\n",
            "userId: 7 training_loss:  3.63465268586346\n",
            "userId: 8 training_loss:  5.696901850897249\n",
            "userId: 9 training_loss:  3.0784762223231903\n",
            "userId: 10 training_loss:  1.2643742916466436\n",
            "userId: 11 training_loss:  2.1839448595245137\n",
            "userId: 12 training_loss:  4.12118513341821\n",
            "userId: 13 training_loss:  3.5803293998250076\n",
            "userId: 14 training_loss:  4.168734916784826\n",
            "userId: 15 training_loss:  1.9153449581605695\n",
            "userId: 16 training_loss:  4.291603020617062\n",
            "userId: 17 training_loss:  1.719158035000874\n",
            "userId: 18 training_loss:  3.3721366344825654\n",
            "userId: 19 training_loss:  3.332244521888582\n",
            "userId: 20 training_loss:  4.050802869420453\n",
            "Evaluating model...\n",
            "computed_loss: 1.5655449230389695\n",
            "Starting round 79\n",
            "userId: 0 training_loss:  5.303469392382932\n",
            "userId: 1 training_loss:  4.2497561903383785\n",
            "userId: 2 training_loss:  3.297436945830598\n",
            "userId: 3 training_loss:  5.009243504003692\n",
            "userId: 4 training_loss:  3.3399581905216067\n",
            "userId: 5 training_loss:  1.206022640032569\n",
            "userId: 6 training_loss:  1.9543703956053804\n",
            "userId: 7 training_loss:  4.243380171635122\n",
            "userId: 8 training_loss:  5.626053229830197\n",
            "userId: 9 training_loss:  2.869059452711067\n",
            "userId: 10 training_loss:  1.469836307709055\n",
            "userId: 11 training_loss:  3.352672230855778\n",
            "userId: 12 training_loss:  3.8099292238139717\n",
            "userId: 13 training_loss:  3.98079014144946\n",
            "userId: 14 training_loss:  3.689214943186104\n",
            "userId: 15 training_loss:  2.320418491489151\n",
            "userId: 16 training_loss:  3.2422838533447433\n",
            "userId: 17 training_loss:  2.064647781179371\n",
            "userId: 18 training_loss:  3.2827204099114207\n",
            "userId: 19 training_loss:  3.6274640216393204\n",
            "userId: 20 training_loss:  3.3964122880298246\n",
            "Evaluating model...\n",
            "computed_loss: 1.2353359974299076\n",
            "Starting round 80\n",
            "userId: 0 training_loss:  4.783753457700971\n",
            "userId: 1 training_loss:  5.3960226151107715\n",
            "userId: 2 training_loss:  2.5809170749887356\n",
            "userId: 3 training_loss:  3.472020731495256\n",
            "userId: 4 training_loss:  3.2663664257068836\n",
            "userId: 5 training_loss:  1.251475391155696\n",
            "userId: 6 training_loss:  1.6932175042780209\n",
            "userId: 7 training_loss:  3.812588043600352\n",
            "userId: 8 training_loss:  4.868618501594634\n",
            "userId: 9 training_loss:  3.400421924604577\n",
            "userId: 10 training_loss:  1.2199414891629063\n",
            "userId: 11 training_loss:  2.9971964989317903\n",
            "userId: 12 training_loss:  3.53538734484588\n",
            "userId: 13 training_loss:  3.9096990149792994\n",
            "userId: 14 training_loss:  3.377501148860632\n",
            "userId: 15 training_loss:  2.008489567567692\n",
            "userId: 16 training_loss:  2.1649668842750227\n",
            "userId: 17 training_loss:  2.4019673633807894\n",
            "userId: 18 training_loss:  3.173491999144363\n",
            "userId: 19 training_loss:  3.721965945581047\n",
            "userId: 20 training_loss:  3.7365106281229665\n",
            "Evaluating model...\n",
            "computed_loss: 1.4408966216842027\n",
            "Starting round 81\n",
            "userId: 0 training_loss:  5.365963259621753\n",
            "userId: 1 training_loss:  4.7126487675400615\n",
            "userId: 2 training_loss:  3.094322627219842\n",
            "userId: 3 training_loss:  4.156282953300678\n",
            "userId: 4 training_loss:  3.140230634928529\n",
            "userId: 5 training_loss:  1.0857259981196286\n",
            "userId: 6 training_loss:  1.6037083746857583\n",
            "userId: 7 training_loss:  3.881223081316186\n",
            "userId: 8 training_loss:  5.50119249467683\n",
            "userId: 9 training_loss:  3.431462629099508\n",
            "userId: 10 training_loss:  1.3487179479642415\n",
            "userId: 11 training_loss:  3.1448992889648233\n",
            "userId: 12 training_loss:  3.8348471969991893\n",
            "userId: 13 training_loss:  3.8057857767351364\n",
            "userId: 14 training_loss:  3.3751281221367093\n",
            "userId: 15 training_loss:  2.310474037920634\n",
            "userId: 16 training_loss:  3.0395314239383855\n",
            "userId: 17 training_loss:  2.14911120690065\n",
            "userId: 18 training_loss:  2.9381898548669856\n",
            "userId: 19 training_loss:  3.7230507632936494\n",
            "userId: 20 training_loss:  4.441890375370905\n",
            "Evaluating model...\n",
            "computed_loss: 1.2573777064865659\n",
            "Starting round 82\n",
            "userId: 0 training_loss:  4.448795331852201\n",
            "userId: 1 training_loss:  4.606602146298398\n",
            "userId: 2 training_loss:  2.967894436072747\n",
            "userId: 3 training_loss:  3.190649196664866\n",
            "userId: 4 training_loss:  2.963194801431909\n",
            "userId: 5 training_loss:  1.0053969378741503\n",
            "userId: 6 training_loss:  1.6997094478063226\n",
            "userId: 7 training_loss:  4.091081710403656\n",
            "userId: 8 training_loss:  6.081999234457517\n",
            "userId: 9 training_loss:  3.0529396978000687\n",
            "userId: 10 training_loss:  1.3395433776907226\n",
            "userId: 11 training_loss:  3.0463820068107306\n",
            "userId: 12 training_loss:  3.5771019204506764\n",
            "userId: 13 training_loss:  4.2555619171043135\n",
            "userId: 14 training_loss:  3.790563487417349\n",
            "userId: 15 training_loss:  2.0445881950806957\n",
            "userId: 16 training_loss:  2.5709794698052137\n",
            "userId: 17 training_loss:  2.1639589873724283\n",
            "userId: 18 training_loss:  3.323988588629028\n",
            "userId: 19 training_loss:  3.911846804054077\n",
            "userId: 20 training_loss:  4.592102362727388\n",
            "Evaluating model...\n",
            "computed_loss: 1.4160881778385768\n",
            "Starting round 83\n",
            "userId: 0 training_loss:  5.237782223368817\n",
            "userId: 1 training_loss:  3.7781468954706354\n",
            "userId: 2 training_loss:  2.724922883229996\n",
            "userId: 3 training_loss:  4.21129823136475\n",
            "userId: 4 training_loss:  3.205045997909052\n",
            "userId: 5 training_loss:  1.0988655404352072\n",
            "userId: 6 training_loss:  1.6605619368463447\n",
            "userId: 7 training_loss:  4.171178107284107\n",
            "userId: 8 training_loss:  5.486260050500746\n",
            "userId: 9 training_loss:  3.3426126486393364\n",
            "userId: 10 training_loss:  1.3192836879711127\n",
            "userId: 11 training_loss:  3.268532631479836\n",
            "userId: 12 training_loss:  3.70500240761751\n",
            "userId: 13 training_loss:  4.722750228774255\n",
            "userId: 14 training_loss:  2.829836625216084\n",
            "userId: 15 training_loss:  2.0829243781345594\n",
            "userId: 16 training_loss:  2.7117204061816067\n",
            "userId: 17 training_loss:  1.8752555498795611\n",
            "userId: 18 training_loss:  3.1520740551258752\n",
            "userId: 19 training_loss:  4.129763535737113\n",
            "userId: 20 training_loss:  4.529496763674619\n",
            "Evaluating model...\n",
            "computed_loss: 1.4080033801307894\n",
            "Starting round 84\n",
            "userId: 0 training_loss:  5.058764684934888\n",
            "userId: 1 training_loss:  4.126228721766902\n",
            "userId: 2 training_loss:  2.946091833068671\n",
            "userId: 3 training_loss:  3.4440698390549436\n",
            "userId: 4 training_loss:  3.033247316547091\n",
            "userId: 5 training_loss:  1.071777992330272\n",
            "userId: 6 training_loss:  1.7500997748455778\n",
            "userId: 7 training_loss:  4.404994065691649\n",
            "userId: 8 training_loss:  5.7610168789544\n",
            "userId: 9 training_loss:  2.9128170167713185\n",
            "userId: 10 training_loss:  1.4229064168915244\n",
            "userId: 11 training_loss:  3.359785853108457\n",
            "userId: 12 training_loss:  3.402799826029881\n",
            "userId: 13 training_loss:  4.757918106551951\n",
            "userId: 14 training_loss:  3.335883551687131\n",
            "userId: 15 training_loss:  1.9606380413651112\n",
            "userId: 16 training_loss:  3.2945964998966\n",
            "userId: 17 training_loss:  2.0638294189666118\n",
            "userId: 18 training_loss:  3.116184155395102\n",
            "userId: 19 training_loss:  3.405066923523622\n",
            "userId: 20 training_loss:  3.3169448157153987\n",
            "Evaluating model...\n",
            "computed_loss: 1.3259780540767578\n",
            "Starting round 85\n",
            "userId: 0 training_loss:  4.7672249226368155\n",
            "userId: 1 training_loss:  3.8392287765049624\n",
            "userId: 2 training_loss:  2.909336378652146\n",
            "userId: 3 training_loss:  3.443922248387735\n",
            "userId: 4 training_loss:  3.4137747830504104\n",
            "userId: 5 training_loss:  1.1230188056988022\n",
            "userId: 6 training_loss:  1.6754763883003652\n",
            "userId: 7 training_loss:  3.7711823889302876\n",
            "userId: 8 training_loss:  5.643975734974427\n",
            "userId: 9 training_loss:  3.0903823045651917\n",
            "userId: 10 training_loss:  1.29852628524642\n",
            "userId: 11 training_loss:  3.0829838260459073\n",
            "userId: 12 training_loss:  4.4548428086692295\n",
            "userId: 13 training_loss:  3.5600494536640026\n",
            "userId: 14 training_loss:  3.041571872575578\n",
            "userId: 15 training_loss:  2.117285755451017\n",
            "userId: 16 training_loss:  2.986245605966971\n",
            "userId: 17 training_loss:  2.2829687814826207\n",
            "userId: 18 training_loss:  3.2867987624394486\n",
            "userId: 19 training_loss:  3.2848719758044935\n",
            "userId: 20 training_loss:  4.073840267116727\n",
            "Evaluating model...\n",
            "computed_loss: 1.3470976467307483\n",
            "Starting round 86\n",
            "userId: 0 training_loss:  4.976520111452961\n",
            "userId: 1 training_loss:  4.558696199261833\n",
            "userId: 2 training_loss:  2.9854728818739558\n",
            "userId: 3 training_loss:  4.057820416863907\n",
            "userId: 4 training_loss:  2.642741078673585\n",
            "userId: 5 training_loss:  1.0352075610516764\n",
            "userId: 6 training_loss:  1.7628108201195443\n",
            "userId: 7 training_loss:  3.742393774392957\n",
            "userId: 8 training_loss:  5.487098033212816\n",
            "userId: 9 training_loss:  3.501832907819682\n",
            "userId: 10 training_loss:  1.3629427418845403\n",
            "userId: 11 training_loss:  2.6254164577152745\n",
            "userId: 12 training_loss:  4.156772963200597\n",
            "userId: 13 training_loss:  4.684106880099681\n",
            "userId: 14 training_loss:  3.002185751715884\n",
            "userId: 15 training_loss:  2.3658135537361478\n",
            "userId: 16 training_loss:  2.9928281725608707\n",
            "userId: 17 training_loss:  2.372401268568261\n",
            "userId: 18 training_loss:  3.1931164172020914\n",
            "userId: 19 training_loss:  3.4923206741114647\n",
            "userId: 20 training_loss:  3.6049885949670766\n",
            "Evaluating model...\n",
            "computed_loss: 1.49813772329989\n",
            "Starting round 87\n",
            "userId: 0 training_loss:  5.329134924138362\n",
            "userId: 1 training_loss:  4.262832452056584\n",
            "userId: 2 training_loss:  2.844610481391977\n",
            "userId: 3 training_loss:  4.1341262057853125\n",
            "userId: 4 training_loss:  2.676734767166813\n",
            "userId: 5 training_loss:  1.137235016639242\n",
            "userId: 6 training_loss:  1.7796327738068531\n",
            "userId: 7 training_loss:  3.966070333770836\n",
            "userId: 8 training_loss:  5.86612081344643\n",
            "userId: 9 training_loss:  2.5500499802419183\n",
            "userId: 10 training_loss:  1.2435362527822669\n",
            "userId: 11 training_loss:  2.706562988348437\n",
            "userId: 12 training_loss:  3.641718463276649\n",
            "userId: 13 training_loss:  4.155785507239501\n",
            "userId: 14 training_loss:  3.1213954101321146\n",
            "userId: 15 training_loss:  2.5122705850467493\n",
            "userId: 16 training_loss:  2.613680696126271\n",
            "userId: 17 training_loss:  2.1119016585159285\n",
            "userId: 18 training_loss:  3.55132850910365\n",
            "userId: 19 training_loss:  4.295127639802103\n",
            "userId: 20 training_loss:  3.8539340886019255\n",
            "Evaluating model...\n",
            "computed_loss: 1.3106068849317931\n",
            "Starting round 88\n",
            "userId: 0 training_loss:  4.745532594271433\n",
            "userId: 1 training_loss:  4.660394435161118\n",
            "userId: 2 training_loss:  2.9526328135616877\n",
            "userId: 3 training_loss:  3.7415392234304656\n",
            "userId: 4 training_loss:  3.1532836537352074\n",
            "userId: 5 training_loss:  0.9275293530649631\n",
            "userId: 6 training_loss:  1.6567281361979824\n",
            "userId: 7 training_loss:  4.182002158707742\n",
            "userId: 8 training_loss:  5.352415936700384\n",
            "userId: 9 training_loss:  2.7396814175658477\n",
            "userId: 10 training_loss:  1.2566775496621516\n",
            "userId: 11 training_loss:  2.9581541049419013\n",
            "userId: 12 training_loss:  3.36660622882939\n",
            "userId: 13 training_loss:  4.907062110620929\n",
            "userId: 14 training_loss:  2.6782459998147288\n",
            "userId: 15 training_loss:  2.038000333301126\n",
            "userId: 16 training_loss:  4.073443236926343\n",
            "userId: 17 training_loss:  1.767808927185801\n",
            "userId: 18 training_loss:  3.0537542289562722\n",
            "userId: 19 training_loss:  3.002366621361083\n",
            "userId: 20 training_loss:  3.814165685024592\n",
            "Evaluating model...\n",
            "computed_loss: 1.2874990902234826\n",
            "Starting round 89\n",
            "userId: 0 training_loss:  4.828925404855923\n",
            "userId: 1 training_loss:  4.876057714282487\n",
            "userId: 2 training_loss:  3.2460833188039593\n",
            "userId: 3 training_loss:  3.508751926054147\n",
            "userId: 4 training_loss:  2.72128204116093\n",
            "userId: 5 training_loss:  1.0835527799045122\n",
            "userId: 6 training_loss:  1.5746426248370649\n",
            "userId: 7 training_loss:  3.6786624108692023\n",
            "userId: 8 training_loss:  5.510629532961238\n",
            "userId: 9 training_loss:  2.8819680148063758\n",
            "userId: 10 training_loss:  1.2746781474003157\n",
            "userId: 11 training_loss:  3.499495166671256\n",
            "userId: 12 training_loss:  3.3839153059447895\n",
            "userId: 13 training_loss:  3.7576401986015724\n",
            "userId: 14 training_loss:  3.6399160781707813\n",
            "userId: 15 training_loss:  1.8790069174627568\n",
            "userId: 16 training_loss:  2.9567950304836925\n",
            "userId: 17 training_loss:  2.2989823657387842\n",
            "userId: 18 training_loss:  3.36667927770637\n",
            "userId: 19 training_loss:  4.3441510101075345\n",
            "userId: 20 training_loss:  3.888866423247822\n",
            "Evaluating model...\n",
            "computed_loss: 1.3689924229602117\n",
            "Starting round 90\n",
            "userId: 0 training_loss:  5.058898484159566\n",
            "userId: 1 training_loss:  4.219553235751174\n",
            "userId: 2 training_loss:  3.3939065790071212\n",
            "userId: 3 training_loss:  3.4724896472801063\n",
            "userId: 4 training_loss:  2.99101816108705\n",
            "userId: 5 training_loss:  1.1602996919099413\n",
            "userId: 6 training_loss:  1.6741119045817563\n",
            "userId: 7 training_loss:  3.724631834461042\n",
            "userId: 8 training_loss:  5.300315794018241\n",
            "userId: 9 training_loss:  4.199936949889539\n",
            "userId: 10 training_loss:  1.4504793527832802\n",
            "userId: 11 training_loss:  3.158496590870657\n",
            "userId: 12 training_loss:  3.125189241912158\n",
            "userId: 13 training_loss:  4.652209419102447\n",
            "userId: 14 training_loss:  3.0514024837077187\n",
            "userId: 15 training_loss:  2.3778014710938145\n",
            "userId: 16 training_loss:  4.14777973666431\n",
            "userId: 17 training_loss:  2.328012161677851\n",
            "userId: 18 training_loss:  3.4217488559157787\n",
            "userId: 19 training_loss:  3.5204971110695182\n",
            "userId: 20 training_loss:  3.4134750123952076\n",
            "Evaluating model...\n",
            "computed_loss: 1.3662511791336993\n",
            "Starting round 91\n",
            "userId: 0 training_loss:  5.488182685812971\n",
            "userId: 1 training_loss:  4.66553979902219\n",
            "userId: 2 training_loss:  2.544044739346747\n",
            "userId: 3 training_loss:  4.140536379365286\n",
            "userId: 4 training_loss:  2.820916786273573\n",
            "userId: 5 training_loss:  1.0225375847950766\n",
            "userId: 6 training_loss:  1.6936191446494253\n",
            "userId: 7 training_loss:  4.457219163700552\n",
            "userId: 8 training_loss:  5.804441900391169\n",
            "userId: 9 training_loss:  3.1177056928301345\n",
            "userId: 10 training_loss:  1.3138762542740494\n",
            "userId: 11 training_loss:  3.471413072035675\n",
            "userId: 12 training_loss:  3.3731394315559533\n",
            "userId: 13 training_loss:  5.083269830671032\n",
            "userId: 14 training_loss:  3.192650211680024\n",
            "userId: 15 training_loss:  2.21819568723718\n",
            "userId: 16 training_loss:  3.470631312395234\n",
            "userId: 17 training_loss:  2.1022460013676216\n",
            "userId: 18 training_loss:  3.748284190519791\n",
            "userId: 19 training_loss:  4.121755321231221\n",
            "userId: 20 training_loss:  3.08517806964747\n",
            "Evaluating model...\n",
            "computed_loss: 1.2826729417540574\n",
            "Starting round 92\n",
            "userId: 0 training_loss:  5.602209911972837\n",
            "userId: 1 training_loss:  4.198756745069402\n",
            "userId: 2 training_loss:  2.6925516809981516\n",
            "userId: 3 training_loss:  3.374019725610779\n",
            "userId: 4 training_loss:  2.948274289417579\n",
            "userId: 5 training_loss:  0.863191364527139\n",
            "userId: 6 training_loss:  1.5949171264147304\n",
            "userId: 7 training_loss:  4.027446284773242\n",
            "userId: 8 training_loss:  5.426232388386177\n",
            "userId: 9 training_loss:  3.0824832563981865\n",
            "userId: 10 training_loss:  1.3042862151003907\n",
            "userId: 11 training_loss:  3.394735575623205\n",
            "userId: 12 training_loss:  4.121392379332875\n",
            "userId: 13 training_loss:  4.7483568601451065\n",
            "userId: 14 training_loss:  3.6435297690134156\n",
            "userId: 15 training_loss:  2.3278406047234284\n",
            "userId: 16 training_loss:  2.7712941983918933\n",
            "userId: 17 training_loss:  2.147458819361369\n",
            "userId: 18 training_loss:  3.3828095124940796\n",
            "userId: 19 training_loss:  2.998227203801261\n",
            "userId: 20 training_loss:  4.015637019828302\n",
            "Evaluating model...\n",
            "computed_loss: 1.3401407543924744\n",
            "Starting round 93\n",
            "userId: 0 training_loss:  5.199025315350497\n",
            "userId: 1 training_loss:  4.512186778982866\n",
            "userId: 2 training_loss:  3.5643654696322273\n",
            "userId: 3 training_loss:  3.607497592406747\n",
            "userId: 4 training_loss:  2.811099685815951\n",
            "userId: 5 training_loss:  1.0190265794576905\n",
            "userId: 6 training_loss:  1.8285081883861676\n",
            "userId: 7 training_loss:  4.457234248085858\n",
            "userId: 8 training_loss:  5.486118229228374\n",
            "userId: 9 training_loss:  2.660552732812276\n",
            "userId: 10 training_loss:  1.5081482165537985\n",
            "userId: 11 training_loss:  2.9826508806228396\n",
            "userId: 12 training_loss:  4.935715799724176\n",
            "userId: 13 training_loss:  4.100735958318101\n",
            "userId: 14 training_loss:  3.2017054027906378\n",
            "userId: 15 training_loss:  2.094760242239386\n",
            "userId: 16 training_loss:  3.7417886551768698\n",
            "userId: 17 training_loss:  2.2288418712548737\n",
            "userId: 18 training_loss:  3.1605468446303044\n",
            "userId: 19 training_loss:  3.405239515843339\n",
            "userId: 20 training_loss:  4.082843729341731\n",
            "Evaluating model...\n",
            "computed_loss: 1.342783403904557\n",
            "Starting round 94\n",
            "userId: 0 training_loss:  5.372128030235706\n",
            "userId: 1 training_loss:  4.623170148090125\n",
            "userId: 2 training_loss:  3.6288665505163538\n",
            "userId: 3 training_loss:  3.4978685040097766\n",
            "userId: 4 training_loss:  4.076822285303815\n",
            "userId: 5 training_loss:  1.1835194452531483\n",
            "userId: 6 training_loss:  1.5289410092970352\n",
            "userId: 7 training_loss:  4.618481593527681\n",
            "userId: 8 training_loss:  5.878424421554449\n",
            "userId: 9 training_loss:  2.7535788143023447\n",
            "userId: 10 training_loss:  1.3590936845969774\n",
            "userId: 11 training_loss:  4.420262210094775\n",
            "userId: 12 training_loss:  3.692299306424668\n",
            "userId: 13 training_loss:  4.237686720337505\n",
            "userId: 14 training_loss:  2.928775331857548\n",
            "userId: 15 training_loss:  2.2946511428594234\n",
            "userId: 16 training_loss:  2.9077389733466137\n",
            "userId: 17 training_loss:  2.2197851137053783\n",
            "userId: 18 training_loss:  3.0904719635131324\n",
            "userId: 19 training_loss:  3.107417479102036\n",
            "userId: 20 training_loss:  4.192168451259748\n",
            "Evaluating model...\n",
            "computed_loss: 1.3854018637476553\n",
            "Starting round 95\n",
            "userId: 0 training_loss:  5.151878402763326\n",
            "userId: 1 training_loss:  4.827927732337243\n",
            "userId: 2 training_loss:  3.405994072306169\n",
            "userId: 3 training_loss:  4.222436586363855\n",
            "userId: 4 training_loss:  3.0674117558276093\n",
            "userId: 5 training_loss:  1.1404841983874934\n",
            "userId: 6 training_loss:  1.7170434571279256\n",
            "userId: 7 training_loss:  3.772077101781246\n",
            "userId: 8 training_loss:  5.590480444709668\n",
            "userId: 9 training_loss:  3.1805131011645367\n",
            "userId: 10 training_loss:  1.249363189249364\n",
            "userId: 11 training_loss:  3.3358197099371893\n",
            "userId: 12 training_loss:  3.7893907132849547\n",
            "userId: 13 training_loss:  4.163181480224333\n",
            "userId: 14 training_loss:  2.80776767458931\n",
            "userId: 15 training_loss:  2.4001039598958003\n",
            "userId: 16 training_loss:  2.5112189436432093\n",
            "userId: 17 training_loss:  2.0952617198257637\n",
            "userId: 18 training_loss:  3.369924310735447\n",
            "userId: 19 training_loss:  4.122281009803173\n",
            "userId: 20 training_loss:  3.8587075279277756\n",
            "Evaluating model...\n",
            "computed_loss: 1.330320611378951\n",
            "Starting round 96\n",
            "userId: 0 training_loss:  4.333588064526924\n",
            "userId: 1 training_loss:  5.258783961020752\n",
            "userId: 2 training_loss:  3.202595198764431\n",
            "userId: 3 training_loss:  3.3784230236853845\n",
            "userId: 4 training_loss:  3.37602251867013\n",
            "userId: 5 training_loss:  1.2381036014127702\n",
            "userId: 6 training_loss:  1.596779729151038\n",
            "userId: 7 training_loss:  4.036245063058361\n",
            "userId: 8 training_loss:  5.2002854486869365\n",
            "userId: 9 training_loss:  2.719760606548634\n",
            "userId: 10 training_loss:  1.1630526090610227\n",
            "userId: 11 training_loss:  2.5872961959546\n",
            "userId: 12 training_loss:  3.6778575998552396\n",
            "userId: 13 training_loss:  3.9569184232731507\n",
            "userId: 14 training_loss:  4.086212083855491\n",
            "userId: 15 training_loss:  2.0858860373790153\n",
            "userId: 16 training_loss:  2.4682683453214365\n",
            "userId: 17 training_loss:  2.332318090415781\n",
            "userId: 18 training_loss:  2.830803999296255\n",
            "userId: 19 training_loss:  3.6241899911636013\n",
            "userId: 20 training_loss:  3.695171150224038\n",
            "Evaluating model...\n",
            "computed_loss: 1.2605067738254567\n",
            "Starting round 97\n",
            "userId: 0 training_loss:  5.307936341471931\n",
            "userId: 1 training_loss:  4.0901137073040355\n",
            "userId: 2 training_loss:  2.8955629229148947\n",
            "userId: 3 training_loss:  4.492360726831729\n",
            "userId: 4 training_loss:  3.397731767420634\n",
            "userId: 5 training_loss:  1.0827953372868966\n",
            "userId: 6 training_loss:  1.7122866683281852\n",
            "userId: 7 training_loss:  4.339815286720973\n",
            "userId: 8 training_loss:  5.378289964106681\n",
            "userId: 9 training_loss:  3.2787820743927703\n",
            "userId: 10 training_loss:  1.2574178302384322\n",
            "userId: 11 training_loss:  3.2873328183461616\n",
            "userId: 12 training_loss:  4.340462627769215\n",
            "userId: 13 training_loss:  4.604783150472155\n",
            "userId: 14 training_loss:  3.2672208519601753\n",
            "userId: 15 training_loss:  2.334519014422219\n",
            "userId: 16 training_loss:  3.10920254862852\n",
            "userId: 17 training_loss:  2.163777428464104\n",
            "userId: 18 training_loss:  4.066185421374959\n",
            "userId: 19 training_loss:  3.2799957587285085\n",
            "userId: 20 training_loss:  4.005093859435175\n",
            "Evaluating model...\n",
            "computed_loss: 1.4174898706968673\n",
            "Starting round 98\n",
            "userId: 0 training_loss:  5.084774958884788\n",
            "userId: 1 training_loss:  4.208914510031114\n",
            "userId: 2 training_loss:  2.839823058303648\n",
            "userId: 3 training_loss:  4.224044122586363\n",
            "userId: 4 training_loss:  3.3912070983483873\n",
            "userId: 5 training_loss:  1.1437831874837796\n",
            "userId: 6 training_loss:  1.8377090886485437\n",
            "userId: 7 training_loss:  4.108349794095003\n",
            "userId: 8 training_loss:  4.938550066861621\n",
            "userId: 9 training_loss:  3.4417170878272834\n",
            "userId: 10 training_loss:  1.5521616506300802\n",
            "userId: 11 training_loss:  2.8255553016489814\n",
            "userId: 12 training_loss:  3.3293651803671613\n",
            "userId: 13 training_loss:  4.34770607648549\n",
            "userId: 14 training_loss:  2.9916252439757356\n",
            "userId: 15 training_loss:  2.3813964252916806\n",
            "userId: 16 training_loss:  3.2809419187435074\n",
            "userId: 17 training_loss:  2.642684200639036\n",
            "userId: 18 training_loss:  2.9824901215498025\n",
            "userId: 19 training_loss:  3.7259032317212424\n",
            "userId: 20 training_loss:  3.31921682531105\n",
            "Evaluating model...\n",
            "computed_loss: 1.5534155316400633\n",
            "Starting round 99\n",
            "userId: 0 training_loss:  5.368115119367082\n",
            "userId: 1 training_loss:  4.361075653571623\n",
            "userId: 2 training_loss:  2.8486037929753243\n",
            "userId: 3 training_loss:  3.344996159256013\n",
            "userId: 4 training_loss:  3.2750695094988496\n",
            "userId: 5 training_loss:  0.9935789064819568\n",
            "userId: 6 training_loss:  1.7341397024264995\n",
            "userId: 7 training_loss:  4.025927390712758\n",
            "userId: 8 training_loss:  5.7104411319517485\n",
            "userId: 9 training_loss:  2.718903115150921\n",
            "userId: 10 training_loss:  1.444926727930049\n",
            "userId: 11 training_loss:  2.9222702526836377\n",
            "userId: 12 training_loss:  3.645663970082135\n",
            "userId: 13 training_loss:  4.056254679633085\n",
            "userId: 14 training_loss:  4.08658735356422\n",
            "userId: 15 training_loss:  1.941484209591669\n",
            "userId: 16 training_loss:  3.0584338724168205\n",
            "userId: 17 training_loss:  2.2992706296869128\n",
            "userId: 18 training_loss:  3.2957622333402434\n",
            "userId: 19 training_loss:  4.609416484000692\n",
            "userId: 20 training_loss:  3.709133167105901\n",
            "Evaluating model...\n",
            "computed_loss: 1.5505789467638067\n",
            "Starting round 100\n",
            "userId: 0 training_loss:  5.384889153555737\n",
            "userId: 1 training_loss:  4.62912391579625\n",
            "userId: 2 training_loss:  3.3138885429397895\n",
            "userId: 3 training_loss:  3.2995484376284\n",
            "userId: 4 training_loss:  3.064139908568463\n",
            "userId: 5 training_loss:  0.9911493043945786\n",
            "userId: 6 training_loss:  1.7195217626545123\n",
            "userId: 7 training_loss:  4.110902435254008\n",
            "userId: 8 training_loss:  5.3679420550693555\n",
            "userId: 9 training_loss:  3.0403596104765103\n",
            "userId: 10 training_loss:  1.2628974881085724\n",
            "userId: 11 training_loss:  2.787551060201161\n",
            "userId: 12 training_loss:  3.752707732614001\n",
            "userId: 13 training_loss:  4.280181848616278\n",
            "userId: 14 training_loss:  2.792768726235973\n",
            "userId: 15 training_loss:  2.3778167274276796\n",
            "userId: 16 training_loss:  2.680445248624121\n",
            "userId: 17 training_loss:  2.5799639462381454\n",
            "userId: 18 training_loss:  3.2453664460887937\n",
            "userId: 19 training_loss:  4.859754166988589\n",
            "userId: 20 training_loss:  3.372401130330643\n",
            "Evaluating model...\n",
            "computed_loss: 1.4052560441710715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZdaA4r7fZS0"
      },
      "source": [
        "class MF_bias(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF_bias, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.user_bias = nn.Embedding(num_users, 1)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.item_bias = nn.Embedding(num_items, 1)\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.item_emb.weight.data.uniform_(0,0.05)\n",
        "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        b_u = self.user_bias(u).squeeze()\n",
        "        b_v = self.item_bias(v).squeeze()\n",
        "        return (U*V).sum(1) +  b_u  + b_v"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJuYmvy6fqnk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "8442d98f-ae53-46f4-f24d-b68ed583c6d2"
      },
      "source": [
        "# model = MF_bias(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-98095a86a1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'num_users' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV86th6hfsyU"
      },
      "source": [
        "# train_epocs(model, epochs=10, lr=0.05, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlI3eX5yfusz"
      },
      "source": [
        "# train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD5XdcnZfwZV"
      },
      "source": [
        "# train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoqqAbVwfyxZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}